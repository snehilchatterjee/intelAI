{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08a1af89-6f95-422c-a0f6-a51eae723125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "\n",
    "# python train.py --name face --resize_or_crop resize_and_crop --loadSize 563 --fineSize 512 --label_nc 0 --no_instance --dataroot ../datasets/pix2pix/face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c97c62d-be9f-4911-b8fe-08f66383d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseOptions():\n",
    "    def __init__(self):\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self):    \n",
    "        # experiment specifics\n",
    "        self.parser.add_argument('--name', type=str, default='label2city', help='name of the experiment. It decides where to store samples and models')        \n",
    "        self.parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
    "        self.parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n",
    "        self.parser.add_argument('--model', type=str, default='pix2pixHD', help='which model to use')\n",
    "        self.parser.add_argument('--norm', type=str, default='instance', help='instance normalization or batch normalization')        \n",
    "        self.parser.add_argument('--use_dropout', action='store_true', help='use dropout for the generator')\n",
    "        self.parser.add_argument('--data_type', default=32, type=int, choices=[8, 16, 32], help=\"Supported data type i.e. 8, 16, 32 bit\")\n",
    "        self.parser.add_argument('--verbose', action='store_true', default=False, help='toggles verbose')\n",
    "        self.parser.add_argument('--fp16', action='store_true', default=False, help='train with AMP')\n",
    "        self.parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "\n",
    "        # input/output sizes       \n",
    "        self.parser.add_argument('--batchSize', type=int, default=1, help='input batch size')\n",
    "        self.parser.add_argument('--loadSize', type=int, default=1024, help='scale images to this size')\n",
    "        self.parser.add_argument('--fineSize', type=int, default=512, help='then crop to this size')\n",
    "        self.parser.add_argument('--label_nc', type=int, default=35, help='# of input label channels')\n",
    "        self.parser.add_argument('--input_nc', type=int, default=3, help='# of input image channels')\n",
    "        self.parser.add_argument('--output_nc', type=int, default=3, help='# of output image channels')\n",
    "\n",
    "        # for setting inputs\n",
    "        self.parser.add_argument('--dataroot', type=str, default='./datasets/cityscapes/') \n",
    "        self.parser.add_argument('--resize_or_crop', type=str, default='scale_width', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]')\n",
    "        self.parser.add_argument('--serial_batches', action='store_true', help='if true, takes images in order to make batches, otherwise takes them randomly')        \n",
    "        self.parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data argumentation') \n",
    "        self.parser.add_argument('--nThreads', default=2, type=int, help='# threads for loading data')                \n",
    "        self.parser.add_argument('--max_dataset_size', type=int, default=float(\"inf\"), help='Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.')\n",
    "\n",
    "        # for displays\n",
    "        self.parser.add_argument('--display_winsize', type=int, default=512,  help='display window size')\n",
    "        self.parser.add_argument('--tf_log', action='store_true', help='if specified, use tensorboard logging. Requires tensorflow installed')\n",
    "\n",
    "        # for generator\n",
    "        self.parser.add_argument('--netG', type=str, default='global', help='selects model to use for netG')\n",
    "        self.parser.add_argument('--ngf', type=int, default=64, help='# of gen filters in first conv layer')\n",
    "        self.parser.add_argument('--n_downsample_global', type=int, default=4, help='number of downsampling layers in netG') \n",
    "        self.parser.add_argument('--n_blocks_global', type=int, default=9, help='number of residual blocks in the global generator network')\n",
    "        self.parser.add_argument('--n_blocks_local', type=int, default=3, help='number of residual blocks in the local enhancer network')\n",
    "        self.parser.add_argument('--n_local_enhancers', type=int, default=1, help='number of local enhancers to use')        \n",
    "        self.parser.add_argument('--niter_fix_global', type=int, default=0, help='number of epochs that we only train the outmost local enhancer')        \n",
    "\n",
    "        # for instance-wise features\n",
    "        self.parser.add_argument('--no_instance', action='store_true', help='if specified, do *not* add instance map as input')        \n",
    "        self.parser.add_argument('--instance_feat', action='store_true', help='if specified, add encoded instance features as input')\n",
    "        self.parser.add_argument('--label_feat', action='store_true', help='if specified, add encoded label features as input')        \n",
    "        self.parser.add_argument('--feat_num', type=int, default=3, help='vector length for encoded features')        \n",
    "        self.parser.add_argument('--load_features', action='store_true', help='if specified, load precomputed feature maps')\n",
    "        self.parser.add_argument('--n_downsample_E', type=int, default=4, help='# of downsampling layers in encoder') \n",
    "        self.parser.add_argument('--nef', type=int, default=16, help='# of encoder filters in the first conv layer')        \n",
    "        self.parser.add_argument('--n_clusters', type=int, default=10, help='number of clusters for features')        \n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def parse(self, save=True):\n",
    "        if not self.initialized:\n",
    "            self.initialize()\n",
    "        self.opt = self.parser.parse_args()\n",
    "        self.opt.isTrain = self.isTrain   # train or test\n",
    "\n",
    "        str_ids = self.opt.gpu_ids.split(',')\n",
    "        self.opt.gpu_ids = []\n",
    "        for str_id in str_ids:\n",
    "            id = int(str_id)\n",
    "            if id >= 0:\n",
    "                self.opt.gpu_ids.append(id)\n",
    "        \n",
    "        # set gpu ids\n",
    "        if len(self.opt.gpu_ids) > 0:\n",
    "            torch.cuda.set_device(self.opt.gpu_ids[0])\n",
    "\n",
    "        args = vars(self.opt)\n",
    "\n",
    "        print('------------ Options -------------')\n",
    "        for k, v in sorted(args.items()):\n",
    "            print('%s: %s' % (str(k), str(v)))\n",
    "        print('-------------- End ----------------')\n",
    "\n",
    "        # save to the disk        \n",
    "        expr_dir = os.path.join(self.opt.checkpoints_dir, 'depixie')\n",
    "        util.mkdirs(expr_dir)\n",
    "        if save and not self.opt.continue_train:\n",
    "            file_name = os.path.join(expr_dir, 'opt.txt')\n",
    "            with open(file_name, 'wt') as opt_file:\n",
    "                opt_file.write('------------ Options -------------\\n')\n",
    "                for k, v in sorted(args.items()):\n",
    "                    opt_file.write('%s: %s\\n' % (str(k), str(v)))\n",
    "                opt_file.write('-------------- End ----------------\\n')\n",
    "        return self.opt\n",
    "\n",
    "\n",
    "class TrainOptions(BaseOptions):\n",
    "    def initialize(self):\n",
    "        BaseOptions.initialize(self)\n",
    "        # for displays\n",
    "        self.parser.add_argument('--display_freq', type=int, default=100, help='frequency of showing training results on screen')\n",
    "        self.parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n",
    "        self.parser.add_argument('--save_latest_freq', type=int, default=1000, help='frequency of saving the latest results')\n",
    "        self.parser.add_argument('--save_epoch_freq', type=int, default=10, help='frequency of saving checkpoints at the end of epochs')        \n",
    "        self.parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')\n",
    "        self.parser.add_argument('--debug', action='store_true', help='only do one epoch and displays at each iteration')\n",
    "\n",
    "        # for training\n",
    "        self.parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
    "        self.parser.add_argument('--load_pretrain', type=str, default='', help='load the pretrained model from the specified location')\n",
    "        self.parser.add_argument('--which_epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n",
    "        self.parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n",
    "        self.parser.add_argument('--niter', type=int, default=100, help='# of iter at starting learning rate')\n",
    "        self.parser.add_argument('--niter_decay', type=int, default=100, help='# of iter to linearly decay learning rate to zero')\n",
    "        self.parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "        self.parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
    "\n",
    "        # for discriminators        \n",
    "        self.parser.add_argument('--num_D', type=int, default=2, help='number of discriminators to use')\n",
    "        self.parser.add_argument('--n_layers_D', type=int, default=3, help='only used if which_model_netD==n_layers')\n",
    "        self.parser.add_argument('--ndf', type=int, default=64, help='# of discrim filters in first conv layer')    \n",
    "        self.parser.add_argument('--lambda_feat', type=float, default=10.0, help='weight for feature matching loss')                \n",
    "        self.parser.add_argument('--no_ganFeat_loss', action='store_true', help='if specified, do *not* use discriminator feature matching loss')\n",
    "        self.parser.add_argument('--no_vgg_loss', action='store_true', help='if specified, do *not* use VGG feature matching loss')        \n",
    "        self.parser.add_argument('--no_lsgan', action='store_true', help='do *not* use least square GAN, if false, use vanilla GAN')\n",
    "        self.parser.add_argument('--pool_size', type=int, default=0, help='the size of image buffer that stores previously generated images')\n",
    "\n",
    "        self.isTrain = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06563827-da4b-4648-8a5e-72bccbee442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(torch.nn.Module):\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def initialize(self):\n",
    "        #self.opt = opt\n",
    "        self.gpu_ids = 0                                                           #self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = True                                                        #opt.isTrain\n",
    "        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n",
    "        self.save_dir = os.path.join'./checkpoints', 'depixie')\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # used in test time, no backprop\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        return {}\n",
    "\n",
    "    def save(self, label):\n",
    "        pass\n",
    "\n",
    "    # helper saving function that can be used by subclasses\n",
    "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        torch.save(network.cpu().state_dict(), save_path)\n",
    "        if len(gpu_ids) and torch.cuda.is_available():\n",
    "            network.cuda()\n",
    "\n",
    "    # helper loading function that can be used by subclasses\n",
    "    def load_network(self, network, network_label, epoch_label, save_dir=''):        \n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        if not save_dir:\n",
    "            save_dir = self.save_dir\n",
    "        save_path = os.path.join(save_dir, save_filename)        \n",
    "        if not os.path.isfile(save_path):\n",
    "            print('%s not exists yet!' % save_path)\n",
    "            if network_label == 'G':\n",
    "                raise('Generator must exist!')\n",
    "        else:\n",
    "            #network.load_state_dict(torch.load(save_path))\n",
    "            try:\n",
    "                network.load_state_dict(torch.load(save_path))\n",
    "            except:   \n",
    "                pretrained_dict = torch.load(save_path)                \n",
    "                model_dict = network.state_dict()\n",
    "                try:\n",
    "                    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}                    \n",
    "                    network.load_state_dict(pretrained_dict)\n",
    "                    if(False):                                                                             #self.opt.verbose:\n",
    "                        print('Pretrained network %s has excessive layers; Only loading layers that are used' % network_label)\n",
    "                except:\n",
    "                    print('Pretrained network %s has fewer layers; The following are not initialized:' % network_label)\n",
    "                    for k, v in pretrained_dict.items():                      \n",
    "                        if v.size() == model_dict[k].size():\n",
    "                            model_dict[k] = v\n",
    "\n",
    "                    if sys.version_info >= (3,0):\n",
    "                        not_initialized = set()\n",
    "                    else:\n",
    "                        from sets import Set\n",
    "                        not_initialized = Set()                    \n",
    "\n",
    "                    for k, v in model_dict.items():\n",
    "                        if k not in pretrained_dict or v.size() != pretrained_dict[k].size():\n",
    "                            not_initialized.add(k.split('.')[0])\n",
    "                    \n",
    "                    print(sorted(not_initialized))\n",
    "                    network.load_state_dict(model_dict)                  \n",
    "\n",
    "    def update_learning_rate():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fb2caef-38f2-4412-b56c-15a8f712a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixHDModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'Pix2PixHDModel'\n",
    "    \n",
    "    def init_loss_filter(self, use_gan_feat_loss, use_vgg_loss):\n",
    "        flags = (True,\n",
    "                 use_gan_feat_loss, use_vgg_loss, True, True)\n",
    "        def loss_filter(g_gan, g_gan_feat, g_vgg, d_real, d_fake):\n",
    "            return [l for (l,f) in zip((g_gan,g_gan_feat,g_vgg,d_real,d_fake),flags) if f]\n",
    "        return loss_filter\n",
    "    \n",
    "    def initialize(self):                                                           # ,opt\n",
    "        BaseModel.initialize(self)                                                  # , opt\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.isTrain = True                                                        # opt.isTrain\n",
    "        self.use_features = False                                                   #opt.instance_feat or opt.label_feat\n",
    "        self.gen_features = False                                                   #self.use_features and not self.opt.load_features\n",
    "        input_nc =  3                                                               #opt.label_nc if opt.label_nc != 0 else opt.input_nc\n",
    "\n",
    "        ##### define networks        \n",
    "        # Generator network\n",
    "        netG_input_nc = input_nc        \n",
    "        if not True:                                                                #if not opt.no_instance:\n",
    "            netG_input_nc += 1\n",
    "        if self.use_features:\n",
    "            netG_input_nc += 0                                                           #opt.feat_num  \n",
    "\n",
    "\n",
    "        self.netG = networks.define_G(netG_input_nc,3,64,'global',4,9,1,3,'instance',gpu_ids=self.gpu_ids)            ##### IMPORTANT\n",
    "        \n",
    "            \n",
    "            \n",
    "        #self.netG = networks.define_G(netG_input_nc, opt.output_nc, opt.ngf, opt.netG, \n",
    "        #                              opt.n_downsample_global, opt.n_blocks_global, opt.n_local_enhancers, \n",
    "        #                              opt.n_blocks_local, opt.norm, gpu_ids=self.gpu_ids)        \n",
    "\n",
    "        # Discriminator network\n",
    "        if self.isTrain:\n",
    "            use_sigmoid= False                                                       #use_sigmoid = opt.no_lsgan\n",
    "            netD_input_nc = input_nc + 3                                             #opt.output_nc\n",
    "            if not True:                                                           #if not opt.no_instance:\n",
    "                netD_input_nc += 1\n",
    "\n",
    "            self.netD = networks.define_D(netD_input_nc,64,3,'instance',use_sigmoid,2, not False,gpu_ids=self.gpu_ids)         ###### IMPORTANT\n",
    "            \n",
    "            #self.netD = networks.define_D(netD_input_nc, opt.ndf, opt.n_layers_D, opt.norm, use_sigmoid, \n",
    "            #                              opt.num_D, not opt.no_ganFeat_loss, gpu_ids=self.gpu_ids)\n",
    "\n",
    "        ### Encoder network\n",
    "        if self.gen_features:  \n",
    "            pass\n",
    "            #self.netE = networks.define_G(opt.output_nc, opt.feat_num, opt.nef, 'encoder', \n",
    "            #                              opt.n_downsample_E, norm=opt.norm, gpu_ids=self.gpu_ids)  \n",
    "        if(False):                                                                #self.opt.verbose:\n",
    "                print('---------- Networks initialized -------------')\n",
    "\n",
    "        # load networks\n",
    "\n",
    "        continue_train = False\n",
    "        load_pretrain = False\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if not self.isTrain or continue_train or load_pretrain:\n",
    "            pretrained_path = '' if not self.isTrain else load_pretrain\n",
    "            self.load_network(self.netG, 'G', opt.which_epoch, pretrained_path)            \n",
    "            if self.isTrain:\n",
    "                self.load_network(self.netD, 'D', opt.which_epoch, pretrained_path)  \n",
    "            if self.gen_features:\n",
    "                self.load_network(self.netE, 'E', opt.which_epoch, pretrained_path) \n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        # set loss functions and optimizers\n",
    "        if self.isTrain:\n",
    "            if 0 > 0 and (len(self.gpu_ids)) > 1:\n",
    "                raise NotImplementedError(\"Fake Pool Not Implemented for MultiGPU\")\n",
    "            self.fake_pool = ImagePool(0)\n",
    "            \n",
    "            #if opt.pool_size > 0 and (len(self.gpu_ids)) > 1:\n",
    "            #    raise NotImplementedError(\"Fake Pool Not Implemented for MultiGPU\")\n",
    "            #self.fake_pool = ImagePool(opt.pool_size)\n",
    "            \n",
    "            #self.old_lr = opt.lr\n",
    "            self.old_lr = 0.0002\n",
    "\n",
    "            # define loss functions\n",
    "            self.loss_filter = self.init_loss_filter(not False, not False)\n",
    "            #self.loss_filter = self.init_loss_filter(not opt.no_ganFeat_loss, not opt.no_vgg_loss)\n",
    "            \n",
    "            self.criterionGAN = networks.GANLoss(use_lsgan=not False, tensor=self.Tensor) \n",
    "            #self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor) \n",
    "            self.criterionFeat = torch.nn.L1Loss()\n",
    "            #if not opt.no_vgg_loss:  \n",
    "            if not False:  \n",
    "                self.criterionVGG = networks.VGGLoss(self.gpu_ids)\n",
    "                \n",
    "        \n",
    "            # Names so we can breakout loss\n",
    "            self.loss_names = self.loss_filter('G_GAN','G_GAN_Feat','G_VGG','D_real', 'D_fake')\n",
    "\n",
    "            # initialize optimizers\n",
    "            # optimizer G\n",
    "            #if opt.niter_fix_global > 0: \n",
    "            if(0>0):\n",
    "                import sys\n",
    "                if sys.version_info >= (3,0):\n",
    "                    finetune_list = set()\n",
    "                else:\n",
    "                    from sets import Set\n",
    "                    finetune_list = Set()\n",
    "\n",
    "                params_dict = dict(self.netG.named_parameters())\n",
    "                params = []\n",
    "                for key, value in params_dict.items():       \n",
    "                    if key.startswith('model' + str(1)):                         # local enhancers in inside str (IMPORTANT)                    \n",
    "                        params += [value]\n",
    "                        finetune_list.add(key.split('.')[0])  \n",
    "                #print('------------- Only training the local enhancer network (for %d epochs) ------------' % opt.niter_fix_global)               \n",
    "                print('------------- Only training the local enhancer network (for %d epochs) ------------' % 0)\n",
    "                print('The layers that are finetuned are ', sorted(finetune_list))                         \n",
    "            else:\n",
    "                params = list(self.netG.parameters())\n",
    "            if self.gen_features:              \n",
    "                params += list(self.netE.parameters())  \n",
    "                \n",
    "            #self.optimizer_G = torch.optim.Adam(params, lr=opt.lr, betas=(opt.beta1, 0.999)) \n",
    "            self.optimizer_G = torch.optim.Adam(params, lr=0.0002, betas=(opt.beta1, 0.999)) \n",
    "\n",
    "            # optimizer D                        \n",
    "            params = list(self.netD.parameters())    \n",
    "            #self.optimizer_D = torch.optim.Adam(params, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(params, lr=0.0002, betas=(opt.beta1, 0.999))\n",
    "\n",
    "    def encode_input(self, label_map, inst_map=None, real_image=None, feat_map=None, infer=False):             \n",
    "        if self.opt.label_nc == 0:\n",
    "            input_label = label_map.data.cuda()\n",
    "        else:\n",
    "            # create one-hot vector for label map \n",
    "            size = label_map.size()\n",
    "            oneHot_size = (size[0], self.opt.label_nc, size[2], size[3])\n",
    "            input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "            input_label = input_label.scatter_(1, label_map.data.long().cuda(), 1.0)\n",
    "            if self.opt.data_type == 16:\n",
    "                input_label = input_label.half()\n",
    "\n",
    "        # get edges from instance map\n",
    "        if not True:                                                                     #self.opt.no_instance:\n",
    "            inst_map = inst_map.data.cuda()\n",
    "            edge_map = self.get_edges(inst_map)\n",
    "            input_label = torch.cat((input_label, edge_map), dim=1)         \n",
    "        input_label = Variable(input_label, volatile=infer)\n",
    "\n",
    "        # real images for training\n",
    "        if real_image is not None:\n",
    "            real_image = Variable(real_image.data.cuda())\n",
    "\n",
    "        # instance map for feature encoding\n",
    "        if self.use_features:\n",
    "            # get precomputed feature maps\n",
    "            if self.opt.load_features:\n",
    "                feat_map = Variable(feat_map.data.cuda())\n",
    "            if self.opt.label_feat:\n",
    "                inst_map = label_map.cuda()\n",
    "\n",
    "        return input_label, inst_map, real_image, feat_map\n",
    "\n",
    "    def discriminate(self, input_label, test_image, use_pool=False):\n",
    "        input_concat = torch.cat((input_label, test_image.detach()), dim=1)\n",
    "        if use_pool:            \n",
    "            fake_query = self.fake_pool.query(input_concat)\n",
    "            return self.netD.forward(fake_query)\n",
    "        else:\n",
    "            return self.netD.forward(input_concat)\n",
    "\n",
    "    def forward(self, label, inst, image, feat, infer=False):\n",
    "        # Encode Inputs\n",
    "        input_label, inst_map, real_image, feat_map = self.encode_input(label, inst, image, feat)  \n",
    "\n",
    "        # Fake Generation\n",
    "        if self.use_features:\n",
    "            if not self.opt.load_features:\n",
    "                feat_map = self.netE.forward(real_image, inst_map)                     \n",
    "            input_concat = torch.cat((input_label, feat_map), dim=1)                        \n",
    "        else:\n",
    "            input_concat = input_label\n",
    "        fake_image = self.netG.forward(input_concat)\n",
    "\n",
    "        # Fake Detection and Loss\n",
    "        pred_fake_pool = self.discriminate(input_label, fake_image, use_pool=True)\n",
    "        loss_D_fake = self.criterionGAN(pred_fake_pool, False)        \n",
    "\n",
    "        # Real Detection and Loss        \n",
    "        pred_real = self.discriminate(input_label, real_image)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "\n",
    "        # GAN loss (Fake Passability Loss)        \n",
    "        pred_fake = self.netD.forward(torch.cat((input_label, fake_image), dim=1))        \n",
    "        loss_G_GAN = self.criterionGAN(pred_fake, True)               \n",
    "        \n",
    "        # GAN feature matching loss\n",
    "        loss_G_GAN_Feat = 0\n",
    "        #if not self.opt.no_ganFeat_loss:\n",
    "        if not False:\n",
    "            feat_weights = 4.0 / (3 + 1)\n",
    "            #feat_weights = 4.0 / (self.opt.n_layers_D + 1)\n",
    "            D_weights = 1.0 / 2\n",
    "            #D_weights = 1.0 / self.opt.num_D\n",
    "            #for i in range(self.opt.num_D):\n",
    "            for i in range(2):\n",
    "                for j in range(len(pred_fake[i])-1):\n",
    "                    loss_G_GAN_Feat += D_weights * feat_weights * \\\n",
    "                        self.criterionFeat(pred_fake[i][j], pred_real[i][j].detach()) * self.opt.lambda_feat\n",
    "                   \n",
    "        # VGG feature matching loss\n",
    "        loss_G_VGG = 0\n",
    "        #if not self.opt.no_vgg_loss:\n",
    "        if not False:\n",
    "            loss_G_VGG = self.criterionVGG(fake_image, real_image) * self.opt.lambda_feat\n",
    "        \n",
    "        # Only return the fake_B image if necessary to save BW\n",
    "        return [ self.loss_filter( loss_G_GAN, loss_G_GAN_Feat, loss_G_VGG, loss_D_real, loss_D_fake ), None if not infer else fake_image ]\n",
    "\n",
    "    def inference(self, label, inst, image=None):\n",
    "        # Encode Inputs        \n",
    "        image = Variable(image) if image is not None else None\n",
    "        input_label, inst_map, real_image, _ = self.encode_input(Variable(label), Variable(inst), image, infer=True)\n",
    "\n",
    "        # Fake Generation\n",
    "        if self.use_features:\n",
    "            if self.opt.use_encoded_image:\n",
    "                # encode the real image to get feature map\n",
    "                feat_map = self.netE.forward(real_image, inst_map)\n",
    "            else:\n",
    "                # sample clusters from precomputed features             \n",
    "                feat_map = self.sample_features(inst_map)\n",
    "            input_concat = torch.cat((input_label, feat_map), dim=1)                        \n",
    "        else:\n",
    "            input_concat = input_label        \n",
    "           \n",
    "        if torch.__version__.startswith('0.4'):\n",
    "            with torch.no_grad():\n",
    "                fake_image = self.netG.forward(input_concat)\n",
    "        else:\n",
    "            fake_image = self.netG.forward(input_concat)\n",
    "        return fake_image\n",
    "\n",
    "    def sample_features(self, inst): \n",
    "        # read precomputed feature clusters \n",
    "        cluster_path = os.path.join(self.opt.checkpoints_dir, self.opt.name, self.opt.cluster_path)        \n",
    "        features_clustered = np.load(cluster_path, encoding='latin1').item()\n",
    "\n",
    "        # randomly sample from the feature clusters\n",
    "        inst_np = inst.cpu().numpy().astype(int)                                      \n",
    "        feat_map = self.Tensor(inst.size()[0], self.opt.feat_num, inst.size()[2], inst.size()[3])\n",
    "        for i in np.unique(inst_np):    \n",
    "            label = i if i < 1000 else i//1000\n",
    "            if label in features_clustered:\n",
    "                feat = features_clustered[label]\n",
    "                cluster_idx = np.random.randint(0, feat.shape[0]) \n",
    "                                            \n",
    "                idx = (inst == int(i)).nonzero()\n",
    "                for k in range(self.opt.feat_num):                                    \n",
    "                    feat_map[idx[:,0], idx[:,1] + k, idx[:,2], idx[:,3]] = feat[cluster_idx, k]\n",
    "        if self.opt.data_type==16:\n",
    "            feat_map = feat_map.half()\n",
    "        return feat_map\n",
    "\n",
    "    def encode_features(self, image, inst):\n",
    "        image = Variable(image.cuda(), volatile=True)\n",
    "        feat_num = self.opt.feat_num\n",
    "        h, w = inst.size()[2], inst.size()[3]\n",
    "        block_num = 32\n",
    "        feat_map = self.netE.forward(image, inst.cuda())\n",
    "        inst_np = inst.cpu().numpy().astype(int)\n",
    "        feature = {}\n",
    "        for i in range(self.opt.label_nc):\n",
    "            feature[i] = np.zeros((0, feat_num+1))\n",
    "        for i in np.unique(inst_np):\n",
    "            label = i if i < 1000 else i//1000\n",
    "            idx = (inst == int(i)).nonzero()\n",
    "            num = idx.size()[0]\n",
    "            idx = idx[num//2,:]\n",
    "            val = np.zeros((1, feat_num+1))                        \n",
    "            for k in range(feat_num):\n",
    "                val[0, k] = feat_map[idx[0], idx[1] + k, idx[2], idx[3]].data[0]            \n",
    "            val[0, feat_num] = float(num) / (h * w // block_num)\n",
    "            feature[label] = np.append(feature[label], val, axis=0)\n",
    "        return feature\n",
    "\n",
    "    def get_edges(self, t):\n",
    "        edge = torch.cuda.ByteTensor(t.size()).zero_()\n",
    "        edge[:,:,:,1:] = edge[:,:,:,1:] | (t[:,:,:,1:] != t[:,:,:,:-1])\n",
    "        edge[:,:,:,:-1] = edge[:,:,:,:-1] | (t[:,:,:,1:] != t[:,:,:,:-1])\n",
    "        edge[:,:,1:,:] = edge[:,:,1:,:] | (t[:,:,1:,:] != t[:,:,:-1,:])\n",
    "        edge[:,:,:-1,:] = edge[:,:,:-1,:] | (t[:,:,1:,:] != t[:,:,:-1,:])\n",
    "        if self.opt.data_type==16:\n",
    "            return edge.half()\n",
    "        else:\n",
    "            return edge.float()\n",
    "\n",
    "    def save(self, which_epoch):\n",
    "        self.save_network(self.netG, 'G', which_epoch, self.gpu_ids)\n",
    "        self.save_network(self.netD, 'D', which_epoch, self.gpu_ids)\n",
    "        if self.gen_features:\n",
    "            self.save_network(self.netE, 'E', which_epoch, self.gpu_ids)\n",
    "\n",
    "    def update_fixed_params(self):\n",
    "        # after fixing the global generator for a number of iterations, also start finetuning it\n",
    "        params = list(self.netG.parameters())\n",
    "        if self.gen_features:\n",
    "            params += list(self.netE.parameters())           \n",
    "        #self.optimizer_G = torch.optim.Adam(params, lr=self.opt.lr, betas=(self.opt.beta1, 0.999))\n",
    "        self.optimizer_G = torch.optim.Adam(params, lr=self.0.0002, betas=(self.opt.beta1, 0.999))\n",
    "        if(False):                                                                                          #self.opt.verbose:\n",
    "            print('------------ Now also finetuning global generator -----------')\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        #lrd = self.opt.lr / self.opt.niter_decay\n",
    "        lrd = 0.0002 / self.opt.niter_decay\n",
    "        lr = self.old_lr - lrd        \n",
    "        for param_group in self.optimizer_D.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        for param_group in self.optimizer_G.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        if(False):                                                                                           #self.opt.verbose:\n",
    "            print('update learning rate: %f -> %f' % (self.old_lr, lr))\n",
    "        self.old_lr = lr\n",
    "\n",
    "class InferenceModel(Pix2PixHDModel):\n",
    "    def forward(self, inp):\n",
    "        label, inst = inp\n",
    "        return self.inference(label, inst)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dab06-d78b-4f5c-b363-fbaeb843af4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499e40e-dbb3-46fc-bdfe-966ee686beae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
