{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08a1af89-6f95-422c-a0f6-a51eae723125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# python train.py --name face --resize_or_crop resize_and_crop --loadSize 563 --fineSize 512 --label_nc 0 --no_instance --dataroot ../datasets/pix2pix/face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c97c62d-be9f-4911-b8fe-08f66383d59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseOptions():\n",
    "    def __init__(self):\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self):    \n",
    "        # experiment specifics\n",
    "        self.parser.add_argument('--name', type=str, default='label2city', help='name of the experiment. It decides where to store samples and models')        \n",
    "        self.parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
    "        self.parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n",
    "        self.parser.add_argument('--model', type=str, default='pix2pixHD', help='which model to use')\n",
    "        self.parser.add_argument('--norm', type=str, default='instance', help='instance normalization or batch normalization')        \n",
    "        self.parser.add_argument('--use_dropout', action='store_true', help='use dropout for the generator')\n",
    "        self.parser.add_argument('--data_type', default=32, type=int, choices=[8, 16, 32], help=\"Supported data type i.e. 8, 16, 32 bit\")\n",
    "        self.parser.add_argument('--verbose', action='store_true', default=False, help='toggles verbose')\n",
    "        self.parser.add_argument('--fp16', action='store_true', default=False, help='train with AMP')\n",
    "        self.parser.add_argument('--local_rank', type=int, default=0, help='local rank for distributed training')\n",
    "\n",
    "        # input/output sizes       \n",
    "        self.parser.add_argument('--batchSize', type=int, default=1, help='input batch size')\n",
    "        self.parser.add_argument('--loadSize', type=int, default=1024, help='scale images to this size')\n",
    "        self.parser.add_argument('--fineSize', type=int, default=512, help='then crop to this size')\n",
    "        self.parser.add_argument('--label_nc', type=int, default=35, help='# of input label channels')\n",
    "        self.parser.add_argument('--input_nc', type=int, default=3, help='# of input image channels')\n",
    "        self.parser.add_argument('--output_nc', type=int, default=3, help='# of output image channels')\n",
    "\n",
    "        # for setting inputs\n",
    "        self.parser.add_argument('--dataroot', type=str, default='./datasets/cityscapes/') \n",
    "        self.parser.add_argument('--resize_or_crop', type=str, default='scale_width', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]')\n",
    "        self.parser.add_argument('--serial_batches', action='store_true', help='if true, takes images in order to make batches, otherwise takes them randomly')        \n",
    "        self.parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data argumentation') \n",
    "        self.parser.add_argument('--nThreads', default=2, type=int, help='# threads for loading data')                \n",
    "        self.parser.add_argument('--max_dataset_size', type=int, default=float(\"inf\"), help='Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.')\n",
    "\n",
    "        # for displays\n",
    "        self.parser.add_argument('--display_winsize', type=int, default=512,  help='display window size')\n",
    "        self.parser.add_argument('--tf_log', action='store_true', help='if specified, use tensorboard logging. Requires tensorflow installed')\n",
    "\n",
    "        # for generator\n",
    "        self.parser.add_argument('--netG', type=str, default='global', help='selects model to use for netG')\n",
    "        self.parser.add_argument('--ngf', type=int, default=64, help='# of gen filters in first conv layer')\n",
    "        self.parser.add_argument('--n_downsample_global', type=int, default=4, help='number of downsampling layers in netG') \n",
    "        self.parser.add_argument('--n_blocks_global', type=int, default=9, help='number of residual blocks in the global generator network')\n",
    "        self.parser.add_argument('--n_blocks_local', type=int, default=3, help='number of residual blocks in the local enhancer network')\n",
    "        self.parser.add_argument('--n_local_enhancers', type=int, default=1, help='number of local enhancers to use')        \n",
    "        self.parser.add_argument('--niter_fix_global', type=int, default=0, help='number of epochs that we only train the outmost local enhancer')        \n",
    "\n",
    "        # for instance-wise features\n",
    "        self.parser.add_argument('--no_instance', action='store_true', help='if specified, do *not* add instance map as input')        \n",
    "        self.parser.add_argument('--instance_feat', action='store_true', help='if specified, add encoded instance features as input')\n",
    "        self.parser.add_argument('--label_feat', action='store_true', help='if specified, add encoded label features as input')        \n",
    "        self.parser.add_argument('--feat_num', type=int, default=3, help='vector length for encoded features')        \n",
    "        self.parser.add_argument('--load_features', action='store_true', help='if specified, load precomputed feature maps')\n",
    "        self.parser.add_argument('--n_downsample_E', type=int, default=4, help='# of downsampling layers in encoder') \n",
    "        self.parser.add_argument('--nef', type=int, default=16, help='# of encoder filters in the first conv layer')        \n",
    "        self.parser.add_argument('--n_clusters', type=int, default=10, help='number of clusters for features')        \n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def parse(self, save=True):\n",
    "        if not self.initialized:\n",
    "            self.initialize()\n",
    "        self.opt = self.parser.parse_args()\n",
    "        self.opt.isTrain = self.isTrain   # train or test\n",
    "\n",
    "        str_ids = self.opt.gpu_ids.split(',')\n",
    "        self.opt.gpu_ids = []\n",
    "        for str_id in str_ids:\n",
    "            id = int(str_id)\n",
    "            if id >= 0:\n",
    "                self.opt.gpu_ids.append(id)\n",
    "        \n",
    "        # set gpu ids\n",
    "        if len(self.opt.gpu_ids) > 0:\n",
    "            torch.cuda.set_device(self.opt.gpu_ids[0])\n",
    "\n",
    "        args = vars(self.opt)\n",
    "\n",
    "        print('------------ Options -------------')\n",
    "        for k, v in sorted(args.items()):\n",
    "            print('%s: %s' % (str(k), str(v)))\n",
    "        print('-------------- End ----------------')\n",
    "\n",
    "        # save to the disk        \n",
    "        expr_dir = os.path.join(self.opt.checkpoints_dir, 'depixie')\n",
    "        util.mkdirs(expr_dir)\n",
    "        if save and not self.opt.continue_train:\n",
    "            file_name = os.path.join(expr_dir, 'opt.txt')\n",
    "            with open(file_name, 'wt') as opt_file:\n",
    "                opt_file.write('------------ Options -------------\\n')\n",
    "                for k, v in sorted(args.items()):\n",
    "                    opt_file.write('%s: %s\\n' % (str(k), str(v)))\n",
    "                opt_file.write('-------------- End ----------------\\n')\n",
    "        return self.opt\n",
    "\n",
    "\n",
    "class TrainOptions(BaseOptions):\n",
    "    def initialize(self):\n",
    "        BaseOptions.initialize(self)\n",
    "        # for displays\n",
    "        self.parser.add_argument('--display_freq', type=int, default=100, help='frequency of showing training results on screen')\n",
    "        self.parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n",
    "        self.parser.add_argument('--save_latest_freq', type=int, default=1000, help='frequency of saving the latest results')\n",
    "        self.parser.add_argument('--save_epoch_freq', type=int, default=10, help='frequency of saving checkpoints at the end of epochs')        \n",
    "        self.parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')\n",
    "        self.parser.add_argument('--debug', action='store_true', help='only do one epoch and displays at each iteration')\n",
    "\n",
    "        # for training\n",
    "        self.parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
    "        self.parser.add_argument('--load_pretrain', type=str, default='', help='load the pretrained model from the specified location')\n",
    "        self.parser.add_argument('--which_epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n",
    "        self.parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n",
    "        self.parser.add_argument('--niter', type=int, default=100, help='# of iter at starting learning rate')\n",
    "        self.parser.add_argument('--niter_decay', type=int, default=100, help='# of iter to linearly decay learning rate to zero')\n",
    "        self.parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "        self.parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
    "\n",
    "        # for discriminators        \n",
    "        self.parser.add_argument('--num_D', type=int, default=2, help='number of discriminators to use')\n",
    "        self.parser.add_argument('--n_layers_D', type=int, default=3, help='only used if which_model_netD==n_layers')\n",
    "        self.parser.add_argument('--ndf', type=int, default=64, help='# of discrim filters in first conv layer')    \n",
    "        self.parser.add_argument('--lambda_feat', type=float, default=10.0, help='weight for feature matching loss')                \n",
    "        self.parser.add_argument('--no_ganFeat_loss', action='store_true', help='if specified, do *not* use discriminator feature matching loss')\n",
    "        self.parser.add_argument('--no_vgg_loss', action='store_true', help='if specified, do *not* use VGG feature matching loss')        \n",
    "        self.parser.add_argument('--no_lsgan', action='store_true', help='do *not* use least square GAN, if false, use vanilla GAN')\n",
    "        self.parser.add_argument('--pool_size', type=int, default=0, help='the size of image buffer that stores previously generated images')\n",
    "\n",
    "        self.isTrain = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637eed0a-06a7-48ac-adad-6140f59b725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Functions\n",
    "###############################################################################\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "def define_G(input_nc, output_nc, ngf, netG, n_downsample_global=3, n_blocks_global=9, n_local_enhancers=1, \n",
    "             n_blocks_local=3, norm='instance', gpu_ids=[0]):    \n",
    "    norm_layer = get_norm_layer(norm_type=norm)     \n",
    "    if netG == 'global':    \n",
    "        netG = GlobalGenerator(input_nc, output_nc, ngf, n_downsample_global, n_blocks_global, norm_layer)       \n",
    "    elif netG == 'local':        \n",
    "        netG = LocalEnhancer(input_nc, output_nc, ngf, n_downsample_global, n_blocks_global, \n",
    "                                  n_local_enhancers, n_blocks_local, norm_layer)\n",
    "    elif netG == 'encoder':\n",
    "        netG = Encoder(input_nc, output_nc, ngf, n_downsample_global, norm_layer)\n",
    "    else:\n",
    "        raise('generator not implemented!')\n",
    "    print(netG)\n",
    "    if len([0])> 0:\n",
    "        assert(torch.cuda.is_available())   \n",
    "        netG.cuda(gpu_ids[0])\n",
    "    netG.apply(weights_init)\n",
    "    return netG\n",
    "\n",
    "def define_D(input_nc, ndf, n_layers_D, norm='instance', use_sigmoid=False, num_D=1, getIntermFeat=False, gpu_ids=[]):        \n",
    "    norm_layer = get_norm_layer(norm_type=norm)   \n",
    "    netD = MultiscaleDiscriminator(input_nc, ndf, n_layers_D, norm_layer, use_sigmoid, num_D, getIntermFeat)   \n",
    "    print(netD)\n",
    "    if len([0]) > 0:\n",
    "        assert(torch.cuda.is_available())\n",
    "        netD.cuda(gpu_ids[0])\n",
    "    netD.apply(weights_init)\n",
    "    return netD\n",
    "\n",
    "def print_network(net):\n",
    "    if isinstance(net, list):\n",
    "        net = net[0]\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)\n",
    "\n",
    "##############################################################################\n",
    "# Losses\n",
    "##############################################################################\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n",
    "                 tensor=torch.FloatTensor):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.real_label = target_real_label\n",
    "        self.fake_label = target_fake_label\n",
    "        self.real_label_var = None\n",
    "        self.fake_label_var = None\n",
    "        self.Tensor = tensor\n",
    "        if use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        target_tensor = None\n",
    "        if target_is_real:\n",
    "            create_label = ((self.real_label_var is None) or\n",
    "                            (self.real_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
    "                self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var\n",
    "        else:\n",
    "            create_label = ((self.fake_label_var is None) or\n",
    "                            (self.fake_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
    "                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "            target_tensor = self.fake_label_var\n",
    "        return target_tensor\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        if isinstance(input[0], list):\n",
    "            loss = 0\n",
    "            for input_i in input:\n",
    "                pred = input_i[-1]\n",
    "                target_tensor = self.get_target_tensor(pred, target_is_real)\n",
    "                loss += self.loss(pred, target_tensor)\n",
    "            return loss\n",
    "        else:            \n",
    "            target_tensor = self.get_target_tensor(input[-1], target_is_real)\n",
    "            return self.loss(input[-1], target_tensor)\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, gpu_ids):\n",
    "        super(VGGLoss, self).__init__()        \n",
    "        self.vgg = Vgg19().cuda()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]        \n",
    "\n",
    "    def forward(self, x, y):              \n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "        loss = 0\n",
    "        for i in range(len(x_vgg)):\n",
    "            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())        \n",
    "        return loss\n",
    "\n",
    "##############################################################################\n",
    "# Generator\n",
    "##############################################################################\n",
    "class LocalEnhancer(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=32, n_downsample_global=3, n_blocks_global=9, \n",
    "                 n_local_enhancers=1, n_blocks_local=3, norm_layer=nn.BatchNorm2d, padding_type='reflect'):        \n",
    "        super(LocalEnhancer, self).__init__()\n",
    "        self.n_local_enhancers = n_local_enhancers\n",
    "        \n",
    "        ###### global generator model #####           \n",
    "        ngf_global = ngf * (2**n_local_enhancers)\n",
    "        model_global = GlobalGenerator(input_nc, output_nc, ngf_global, n_downsample_global, n_blocks_global, norm_layer).model        \n",
    "        model_global = [model_global[i] for i in range(len(model_global)-3)] # get rid of final convolution layers        \n",
    "        self.model = nn.Sequential(*model_global)                \n",
    "\n",
    "        ###### local enhancer layers #####\n",
    "        for n in range(1, n_local_enhancers+1):\n",
    "            ### downsample            \n",
    "            ngf_global = ngf * (2**(n_local_enhancers-n))\n",
    "            model_downsample = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc, ngf_global, kernel_size=7, padding=0), \n",
    "                                norm_layer(ngf_global), nn.ReLU(True),\n",
    "                                nn.Conv2d(ngf_global, ngf_global * 2, kernel_size=3, stride=2, padding=1), \n",
    "                                norm_layer(ngf_global * 2), nn.ReLU(True)]\n",
    "            ### residual blocks\n",
    "            model_upsample = []\n",
    "            for i in range(n_blocks_local):\n",
    "                model_upsample += [ResnetBlock(ngf_global * 2, padding_type=padding_type, norm_layer=norm_layer)]\n",
    "\n",
    "            ### upsample\n",
    "            model_upsample += [nn.ConvTranspose2d(ngf_global * 2, ngf_global, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
    "                               norm_layer(ngf_global), nn.ReLU(True)]      \n",
    "\n",
    "            ### final convolution\n",
    "            if n == n_local_enhancers:                \n",
    "                model_upsample += [nn.ReflectionPad2d(3), nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]                       \n",
    "            \n",
    "            setattr(self, 'model'+str(n)+'_1', nn.Sequential(*model_downsample))\n",
    "            setattr(self, 'model'+str(n)+'_2', nn.Sequential(*model_upsample))                  \n",
    "        \n",
    "        self.downsample = nn.AvgPool2d(3, stride=2, padding=[1, 1], count_include_pad=False)\n",
    "\n",
    "    def forward(self, input): \n",
    "        ### create input pyramid\n",
    "        input_downsampled = [input]\n",
    "        for i in range(self.n_local_enhancers):\n",
    "            input_downsampled.append(self.downsample(input_downsampled[-1]))\n",
    "\n",
    "        ### output at coarest level\n",
    "        output_prev = self.model(input_downsampled[-1])        \n",
    "        ### build up one layer at a time\n",
    "        for n_local_enhancers in range(1, self.n_local_enhancers+1):\n",
    "            model_downsample = getattr(self, 'model'+str(n_local_enhancers)+'_1')\n",
    "            model_upsample = getattr(self, 'model'+str(n_local_enhancers)+'_2')            \n",
    "            input_i = input_downsampled[self.n_local_enhancers-n_local_enhancers]            \n",
    "            output_prev = model_upsample(model_downsample(input_i) + output_prev)\n",
    "        return output_prev\n",
    "\n",
    "class GlobalGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, n_downsampling=3, n_blocks=9, norm_layer=nn.BatchNorm2d, \n",
    "                 padding_type='reflect'):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(GlobalGenerator, self).__init__()        \n",
    "        activation = nn.ReLU(True)        \n",
    "\n",
    "        model = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0), norm_layer(ngf), activation]\n",
    "        ### downsample\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(ngf * mult * 2), activation]\n",
    "\n",
    "        ### resnet blocks\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, activation=activation, norm_layer=norm_layer)]\n",
    "        \n",
    "        ### upsample         \n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                       norm_layer(int(ngf * mult / 2)), activation]\n",
    "        model += [nn.ReflectionPad2d(3), nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]        \n",
    "        self.model = nn.Sequential(*model)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        return self.model(input)             \n",
    "        \n",
    "# Define a resnet block\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, activation=nn.ReLU(True), use_dropout=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, activation, use_dropout)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, activation, use_dropout):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim),\n",
    "                       activation]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=32, n_downsampling=4, norm_layer=nn.BatchNorm2d):\n",
    "        super(Encoder, self).__init__()        \n",
    "        self.output_nc = output_nc        \n",
    "\n",
    "        model = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0), \n",
    "                 norm_layer(ngf), nn.ReLU(True)]             \n",
    "        ### downsample\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(ngf * mult * 2), nn.ReLU(True)]\n",
    "\n",
    "        ### upsample         \n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                       norm_layer(int(ngf * mult / 2)), nn.ReLU(True)]        \n",
    "\n",
    "        model += [nn.ReflectionPad2d(3), nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]\n",
    "        self.model = nn.Sequential(*model) \n",
    "\n",
    "    def forward(self, input, inst):\n",
    "        outputs = self.model(input)\n",
    "\n",
    "        # instance-wise average pooling\n",
    "        outputs_mean = outputs.clone()\n",
    "        inst_list = np.unique(inst.cpu().numpy().astype(int))        \n",
    "        for i in inst_list:\n",
    "            for b in range(input.size()[0]):\n",
    "                indices = (inst[b:b+1] == int(i)).nonzero() # n x 4            \n",
    "                for j in range(self.output_nc):\n",
    "                    output_ins = outputs[indices[:,0] + b, indices[:,1] + j, indices[:,2], indices[:,3]]                    \n",
    "                    mean_feat = torch.mean(output_ins).expand_as(output_ins)                                        \n",
    "                    outputs_mean[indices[:,0] + b, indices[:,1] + j, indices[:,2], indices[:,3]] = mean_feat                       \n",
    "        return outputs_mean\n",
    "\n",
    "class MultiscaleDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, \n",
    "                 use_sigmoid=False, num_D=3, getIntermFeat=False):\n",
    "        super(MultiscaleDiscriminator, self).__init__()\n",
    "        self.num_D = num_D\n",
    "        self.n_layers = n_layers\n",
    "        self.getIntermFeat = getIntermFeat\n",
    "     \n",
    "        for i in range(num_D):\n",
    "            netD = NLayerDiscriminator(input_nc, ndf, n_layers, norm_layer, use_sigmoid, getIntermFeat)\n",
    "            if getIntermFeat:                                \n",
    "                for j in range(n_layers+2):\n",
    "                    setattr(self, 'scale'+str(i)+'_layer'+str(j), getattr(netD, 'model'+str(j)))                                   \n",
    "            else:\n",
    "                setattr(self, 'layer'+str(i), netD.model)\n",
    "\n",
    "        self.downsample = nn.AvgPool2d(3, stride=2, padding=[1, 1], count_include_pad=False)\n",
    "\n",
    "    def singleD_forward(self, model, input):\n",
    "        if self.getIntermFeat:\n",
    "            result = [input]\n",
    "            for i in range(len(model)):\n",
    "                result.append(model[i](result[-1]))\n",
    "            return result[1:]\n",
    "        else:\n",
    "            return [model(input)]\n",
    "\n",
    "    def forward(self, input):        \n",
    "        num_D = self.num_D\n",
    "        result = []\n",
    "        input_downsampled = input\n",
    "        for i in range(num_D):\n",
    "            if self.getIntermFeat:\n",
    "                model = [getattr(self, 'scale'+str(num_D-1-i)+'_layer'+str(j)) for j in range(self.n_layers+2)]\n",
    "            else:\n",
    "                model = getattr(self, 'layer'+str(num_D-1-i))\n",
    "            result.append(self.singleD_forward(model, input_downsampled))\n",
    "            if i != (num_D-1):\n",
    "                input_downsampled = self.downsample(input_downsampled)\n",
    "        return result\n",
    "        \n",
    "# Defines the PatchGAN discriminator with the specified arguments.\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, getIntermFeat=False):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        self.getIntermFeat = getIntermFeat\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        kw = 4\n",
    "        padw = int(np.ceil((kw-1.0)/2))\n",
    "        sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]\n",
    "\n",
    "        nf = ndf\n",
    "        for n in range(1, n_layers):\n",
    "            nf_prev = nf\n",
    "            nf = min(nf * 2, 512)\n",
    "            sequence += [[\n",
    "                nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=2, padding=padw),\n",
    "                norm_layer(nf), nn.LeakyReLU(0.2, True)\n",
    "            ]]\n",
    "\n",
    "        nf_prev = nf\n",
    "        nf = min(nf * 2, 512)\n",
    "        sequence += [[\n",
    "            nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=1, padding=padw),\n",
    "            norm_layer(nf),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]]\n",
    "\n",
    "        sequence += [[nn.Conv2d(nf, 1, kernel_size=kw, stride=1, padding=padw)]]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [[nn.Sigmoid()]]\n",
    "\n",
    "        if getIntermFeat:\n",
    "            for n in range(len(sequence)):\n",
    "                setattr(self, 'model'+str(n), nn.Sequential(*sequence[n]))\n",
    "        else:\n",
    "            sequence_stream = []\n",
    "            for n in range(len(sequence)):\n",
    "                sequence_stream += sequence[n]\n",
    "            self.model = nn.Sequential(*sequence_stream)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.getIntermFeat:\n",
    "            res = [input]\n",
    "            for n in range(self.n_layers+2):\n",
    "                model = getattr(self, 'model'+str(n))\n",
    "                res.append(model(res[-1]))\n",
    "            return res[1:]\n",
    "        else:\n",
    "            return self.model(input)        \n",
    "\n",
    "from torchvision import models\n",
    "class Vgg19(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(Vgg19, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        for x in range(2):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(2, 7):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(7, 12):\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(12, 21):\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(21, 30):\n",
    "            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h_relu1 = self.slice1(X)\n",
    "        h_relu2 = self.slice2(h_relu1)        \n",
    "        h_relu3 = self.slice3(h_relu2)        \n",
    "        h_relu4 = self.slice4(h_relu3)        \n",
    "        h_relu5 = self.slice5(h_relu4)                \n",
    "        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80551b9-9e37-484a-95c1-f01354e84ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images.data:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06563827-da4b-4648-8a5e-72bccbee442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(torch.nn.Module):\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def initialize(self):\n",
    "        #self.opt = opt\n",
    "        self.gpu_ids = [0]                                                           #self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = True                                                        #opt.isTrain\n",
    "        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n",
    "        self.save_dir = os.path.join('./checkpoints', 'depixie')\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # used in test time, no backprop\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        return {}\n",
    "\n",
    "    def save(self, label):\n",
    "        pass\n",
    "\n",
    "    # helper saving function that can be used by subclasses\n",
    "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        torch.save(network.cpu().state_dict(), save_path)\n",
    "        #if len(gpu_ids) and torch.cuda.is_available():\n",
    "        network.cuda()\n",
    "\n",
    "    # helper loading function that can be used by subclasses\n",
    "    def load_network(self, network, network_label, epoch_label, save_dir=''):        \n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        if not save_dir:\n",
    "            save_dir = self.save_dir\n",
    "        save_path = os.path.join(save_dir, save_filename)        \n",
    "        if not os.path.isfile(save_path):\n",
    "            print('%s not exists yet!' % save_path)\n",
    "            if network_label == 'G':\n",
    "                raise('Generator must exist!')\n",
    "        else:\n",
    "            #network.load_state_dict(torch.load(save_path))\n",
    "            try:\n",
    "                network.load_state_dict(torch.load(save_path))\n",
    "            except:   \n",
    "                pretrained_dict = torch.load(save_path)                \n",
    "                model_dict = network.state_dict()\n",
    "                try:\n",
    "                    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}                    \n",
    "                    network.load_state_dict(pretrained_dict)\n",
    "                    if(False):                                                                             #self.opt.verbose:\n",
    "                        print('Pretrained network %s has excessive layers; Only loading layers that are used' % network_label)\n",
    "                except:\n",
    "                    print('Pretrained network %s has fewer layers; The following are not initialized:' % network_label)\n",
    "                    for k, v in pretrained_dict.items():                      \n",
    "                        if v.size() == model_dict[k].size():\n",
    "                            model_dict[k] = v\n",
    "\n",
    "                    if sys.version_info >= (3,0):\n",
    "                        not_initialized = set()\n",
    "                    else:\n",
    "                        from sets import Set\n",
    "                        not_initialized = Set()                    \n",
    "\n",
    "                    for k, v in model_dict.items():\n",
    "                        if k not in pretrained_dict or v.size() != pretrained_dict[k].size():\n",
    "                            not_initialized.add(k.split('.')[0])\n",
    "                    \n",
    "                    print(sorted(not_initialized))\n",
    "                    network.load_state_dict(model_dict)                  \n",
    "\n",
    "    def update_learning_rate():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb2caef-38f2-4412-b56c-15a8f712a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixHDModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'Pix2PixHDModel'\n",
    "    \n",
    "    def init_loss_filter(self, use_gan_feat_loss, use_vgg_loss):\n",
    "        flags = (True,\n",
    "                 use_gan_feat_loss, use_vgg_loss, True, True)\n",
    "        def loss_filter(g_gan, g_gan_feat, g_vgg, d_real, d_fake):\n",
    "            return [l for (l,f) in zip((g_gan,g_gan_feat,g_vgg,d_real,d_fake),flags) if f]\n",
    "        return loss_filter\n",
    "    \n",
    "    def initialize(self):                                                           # ,opt\n",
    "        BaseModel.initialize(self)                                                  # , opt\n",
    "        \n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.isTrain = True                                                        # opt.isTrain\n",
    "        self.use_features = False                                                   #opt.instance_feat or opt.label_feat\n",
    "        self.gen_features = False                                                   #self.use_features and not self.opt.load_features\n",
    "        input_nc =  3                                                               #opt.label_nc if opt.label_nc != 0 else opt.input_nc\n",
    "\n",
    "        ##### define networks        \n",
    "        # Generator network\n",
    "        netG_input_nc = input_nc        \n",
    "        if not True:                                                                #if not opt.no_instance:\n",
    "            netG_input_nc += 1\n",
    "        if self.use_features:\n",
    "            netG_input_nc += 0                                                           #opt.feat_num  \n",
    "\n",
    "\n",
    "        self.netG = define_G(netG_input_nc,3,64,'global',4,9,1,3,'instance',gpu_ids=self.gpu_ids)            ##### IMPORTANT\n",
    "        \n",
    "            \n",
    "            \n",
    "        #self.netG = networks.define_G(netG_input_nc, opt.output_nc, opt.ngf, opt.netG, \n",
    "        #                              opt.n_downsample_global, opt.n_blocks_global, opt.n_local_enhancers, \n",
    "        #                              opt.n_blocks_local, opt.norm, gpu_ids=self.gpu_ids)        \n",
    "\n",
    "        # Discriminator network\n",
    "        if self.isTrain:\n",
    "            use_sigmoid= False                                                       #use_sigmoid = opt.no_lsgan\n",
    "            netD_input_nc = input_nc + 3                                             #opt.output_nc\n",
    "            if not True:                                                           #if not opt.no_instance:\n",
    "                netD_input_nc += 1\n",
    "\n",
    "            self.netD = define_D(netD_input_nc,64,3,'instance',use_sigmoid,2, not False,gpu_ids=self.gpu_ids)         ###### IMPORTANT\n",
    "            \n",
    "            #self.netD = networks.define_D(netD_input_nc, opt.ndf, opt.n_layers_D, opt.norm, use_sigmoid, \n",
    "            #                              opt.num_D, not opt.no_ganFeat_loss, gpu_ids=self.gpu_ids)\n",
    "\n",
    "        ### Encoder network\n",
    "        if self.gen_features:  \n",
    "            pass\n",
    "            #self.netE = networks.define_G(opt.output_nc, opt.feat_num, opt.nef, 'encoder', \n",
    "            #                              opt.n_downsample_E, norm=opt.norm, gpu_ids=self.gpu_ids)  \n",
    "        if(False):                                                                #self.opt.verbose:\n",
    "                print('---------- Networks initialized -------------')\n",
    "\n",
    "        # load networks\n",
    "\n",
    "        continue_train = False\n",
    "        load_pretrain = False\n",
    "\n",
    "        '''\n",
    "        \n",
    "        if not self.isTrain or continue_train or load_pretrain:\n",
    "            pretrained_path = '' if not self.isTrain else load_pretrain\n",
    "            self.load_network(self.netG, 'G', opt.which_epoch, pretrained_path)            \n",
    "            if self.isTrain:\n",
    "                self.load_network(self.netD, 'D', opt.which_epoch, pretrained_path)  \n",
    "            if self.gen_features:\n",
    "                self.load_network(self.netE, 'E', opt.which_epoch, pretrained_path) \n",
    "\n",
    "\n",
    "        '''\n",
    "\n",
    "        # set loss functions and optimizers\n",
    "        if self.isTrain:\n",
    "            if 0 > 0 and (len(self.gpu_ids)) > 1:\n",
    "                raise NotImplementedError(\"Fake Pool Not Implemented for MultiGPU\")\n",
    "            self.fake_pool = ImagePool(0)\n",
    "            \n",
    "            #if opt.pool_size > 0 and (len(self.gpu_ids)) > 1:\n",
    "            #    raise NotImplementedError(\"Fake Pool Not Implemented for MultiGPU\")\n",
    "            #self.fake_pool = ImagePool(opt.pool_size)\n",
    "            \n",
    "            #self.old_lr = opt.lr\n",
    "            self.old_lr = 0.0002\n",
    "\n",
    "            # define loss functions\n",
    "            self.loss_filter = self.init_loss_filter(not False, not False)\n",
    "            #self.loss_filter = self.init_loss_filter(not opt.no_ganFeat_loss, not opt.no_vgg_loss)\n",
    "            \n",
    "            self.criterionGAN = GANLoss(use_lsgan=not False, tensor=self.Tensor) \n",
    "            #self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor) \n",
    "            self.criterionFeat = torch.nn.L1Loss()\n",
    "            #if not opt.no_vgg_loss:  \n",
    "            if not False:  \n",
    "                self.criterionVGG = VGGLoss(self.gpu_ids)\n",
    "                #self.criterionVGG = networks.VGGLoss(self.gpu_ids)\n",
    "                \n",
    "        \n",
    "            # Names so we can breakout loss\n",
    "            self.loss_names = self.loss_filter('G_GAN','G_GAN_Feat','G_VGG','D_real', 'D_fake')\n",
    "\n",
    "            # initialize optimizers\n",
    "            # optimizer G\n",
    "            #if opt.niter_fix_global > 0: \n",
    "            if(0>0):\n",
    "                import sys\n",
    "                if sys.version_info >= (3,0):\n",
    "                    finetune_list = set()\n",
    "                else:\n",
    "                    from sets import Set\n",
    "                    finetune_list = Set()\n",
    "\n",
    "                params_dict = dict(self.netG.named_parameters())\n",
    "                params = []\n",
    "                for key, value in params_dict.items():       \n",
    "                    if key.startswith('model' + str(1)):                         # local enhancers in inside str (IMPORTANT)                    \n",
    "                        params += [value]\n",
    "                        finetune_list.add(key.split('.')[0])  \n",
    "                #print('------------- Only training the local enhancer network (for %d epochs) ------------' % opt.niter_fix_global)               \n",
    "                print('------------- Only training the local enhancer network (for %d epochs) ------------' % 0)\n",
    "                print('The layers that are finetuned are ', sorted(finetune_list))                         \n",
    "            else:\n",
    "                params = list(self.netG.parameters())\n",
    "            if self.gen_features:              \n",
    "                params += list(self.netE.parameters())  \n",
    "                \n",
    "            #self.optimizer_G = torch.optim.Adam(params, lr=opt.lr, betas=(opt.beta1, 0.999)) \n",
    "            self.optimizer_G = torch.optim.Adam(params, lr=0.0002, betas=(0.5, 0.999)) \n",
    "\n",
    "            # optimizer D                        \n",
    "            params = list(self.netD.parameters())    \n",
    "            #self.optimizer_D = torch.optim.Adam(params, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "            self.optimizer_D = torch.optim.Adam(params, lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "    def encode_input(self, label_map, inst_map=None, real_image=None, feat_map=None, infer=False):             \n",
    "        #if self.opt.label_n == 0:\n",
    "        if 0==0:\n",
    "            input_label = label_map.data.cuda()\n",
    "        else:\n",
    "            # create one-hot vector for label map \n",
    "            size = label_map.size()\n",
    "            #oneHot_size = (size[0], self.opt.label_nc, size[2], size[3])\n",
    "            oneHot_size = (size[0], 0, size[2], size[3])    \n",
    "            input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "            input_label = input_label.scatter_(1, label_map.data.long().cuda(), 1.0)\n",
    "            #if self.opt.data_type == 16:\n",
    "            if(32==16):\n",
    "                input_label = input_label.half()\n",
    "\n",
    "        # get edges from instance map\n",
    "        if not True:                                                                     #self.opt.no_instance:\n",
    "            inst_map = inst_map.data.cuda()\n",
    "            edge_map = self.get_edges(inst_map)\n",
    "            input_label = torch.cat((input_label, edge_map), dim=1)         \n",
    "        input_label = Variable(input_label, volatile=infer)\n",
    "\n",
    "        # real images for training\n",
    "        if real_image is not None:\n",
    "            real_image = Variable(real_image.data.cuda())\n",
    "\n",
    "        # instance map for feature encoding\n",
    "        if self.use_features:\n",
    "            # get precomputed feature maps\n",
    "            #if self.opt.load_features:\n",
    "            if(False):\n",
    "                feat_map = Variable(feat_map.data.cuda())\n",
    "            #if self.opt.label_feat\n",
    "            if(False):\n",
    "                inst_map = label_map.cuda()\n",
    "\n",
    "        return input_label, inst_map, real_image, feat_map\n",
    "\n",
    "    def discriminate(self, input_label, test_image, use_pool=False):\n",
    "        input_concat = torch.cat((input_label, test_image.detach()), dim=1)\n",
    "        if use_pool:            \n",
    "            fake_query = self.fake_pool.query(input_concat)\n",
    "            return self.netD.forward(fake_query)\n",
    "        else:\n",
    "            return self.netD.forward(input_concat)\n",
    "\n",
    "    def forward(self, label, inst, image, feat, infer=False):\n",
    "        # Encode Inputs\n",
    "        input_label, inst_map, real_image, feat_map = self.encode_input(label, inst, image, feat)  \n",
    "\n",
    "        # Fake Generation\n",
    "        if self.use_features:\n",
    "            #if not self.opt.load_features:\n",
    "            if not False:\n",
    "                feat_map = self.netE.forward(real_image, inst_map)                     \n",
    "            input_concat = torch.cat((input_label, feat_map), dim=1)                        \n",
    "        else:\n",
    "            input_concat = input_label\n",
    "        fake_image = self.netG.forward(input_concat)\n",
    "\n",
    "        # Fake Detection and Loss\n",
    "        pred_fake_pool = self.discriminate(input_label, fake_image, use_pool=True)\n",
    "        loss_D_fake = self.criterionGAN(pred_fake_pool, False)        \n",
    "\n",
    "        # Real Detection and Loss        \n",
    "        pred_real = self.discriminate(input_label, real_image)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "\n",
    "        # GAN loss (Fake Passability Loss)        \n",
    "        pred_fake = self.netD.forward(torch.cat((input_label, fake_image), dim=1))        \n",
    "        loss_G_GAN = self.criterionGAN(pred_fake, True)               \n",
    "        \n",
    "        # GAN feature matching loss\n",
    "        loss_G_GAN_Feat = 0\n",
    "        #if not self.opt.no_ganFeat_loss:\n",
    "        if not False:\n",
    "            feat_weights = 4.0 / (3 + 1)\n",
    "            #feat_weights = 4.0 / (self.opt.n_layers_D + 1)\n",
    "            D_weights = 1.0 / 2\n",
    "            #D_weights = 1.0 / self.opt.num_D\n",
    "            #for i in range(self.opt.num_D):\n",
    "            for i in range(2):\n",
    "                for j in range(len(pred_fake[i])-1):\n",
    "                    loss_G_GAN_Feat += D_weights * feat_weights * \\\n",
    "                        self.criterionFeat(pred_fake[i][j], pred_real[i][j].detach()) * 10.0                  #self.criterionFeat(pred_fake[i][j], pred_real[i][j].detach()) * self.opt.lambda_feat\n",
    "                   \n",
    "        # VGG feature matching loss\n",
    "        loss_G_VGG = 0\n",
    "        #if not self.opt.no_vgg_loss:\n",
    "        if not False:\n",
    "            #loss_G_VGG = self.criterionVGG(fake_image, real_image) * self.opt.lambda_feat\n",
    "            loss_G_VGG = self.criterionVGG(fake_image, real_image) * 10.0\n",
    "        \n",
    "        # Only return the fake_B image if necessary to save BW\n",
    "        return [ self.loss_filter( loss_G_GAN, loss_G_GAN_Feat, loss_G_VGG, loss_D_real, loss_D_fake ), fake_image ]\n",
    "\n",
    "    def inference(self, label, inst, image=None):\n",
    "        # Encode Inputs        \n",
    "        image = Variable(image) if image is not None else None\n",
    "        input_label, inst_map, real_image, _ = self.encode_input(Variable(label), Variable(inst), image, infer=True)\n",
    "\n",
    "        # Fake Generation\n",
    "        if self.use_features:\n",
    "            if self.opt.use_encoded_image:\n",
    "                # encode the real image to get feature map\n",
    "                feat_map = self.netE.forward(real_image, inst_map)\n",
    "            else:\n",
    "                # sample clusters from precomputed features             \n",
    "                feat_map = self.sample_features(inst_map)\n",
    "            input_concat = torch.cat((input_label, feat_map), dim=1)                        \n",
    "        else:\n",
    "            input_concat = input_label        \n",
    "           \n",
    "        if torch.__version__.startswith('0.4'):\n",
    "            with torch.no_grad():\n",
    "                fake_image = self.netG.forward(input_concat)\n",
    "        else:\n",
    "            fake_image = self.netG.forward(input_concat)\n",
    "        return fake_image\n",
    "\n",
    "    def sample_features(self, inst): \n",
    "        # read precomputed feature clusters \n",
    "        #cluster_path = os.path.join(self.opt.checkpoints_dir, self.opt.name, self.opt.cluster_path)\n",
    "        cluster_path = os.path.join('./checkpoints', 'depixie', self.opt.cluster_path)\n",
    "        features_clustered = np.load(cluster_path, encoding='latin1').item()\n",
    "\n",
    "        # randomly sample from the feature clusters\n",
    "        inst_np = inst.cpu().numpy().astype(int)                                      \n",
    "        feat_map = self.Tensor(inst.size()[0], self.opt.feat_num, inst.size()[2], inst.size()[3])\n",
    "        for i in np.unique(inst_np):    \n",
    "            label = i if i < 1000 else i//1000\n",
    "            if label in features_clustered:\n",
    "                feat = features_clustered[label]\n",
    "                cluster_idx = np.random.randint(0, feat.shape[0]) \n",
    "                                            \n",
    "                idx = (inst == int(i)).nonzero()\n",
    "                for k in range(self.opt.feat_num):                                    \n",
    "                    feat_map[idx[:,0], idx[:,1] + k, idx[:,2], idx[:,3]] = feat[cluster_idx, k]\n",
    "        #if self.opt.data_type==16:\n",
    "        if(32==16):\n",
    "            feat_map = feat_map.half()\n",
    "        return feat_map\n",
    "\n",
    "    def encode_features(self, image, inst):\n",
    "        image = Variable(image.cuda(), volatile=True)\n",
    "        #feat_num = self.opt.feat_num\n",
    "        feat_num = 3\n",
    "        h, w = inst.size()[2], inst.size()[3]\n",
    "        block_num = 32\n",
    "        feat_map = self.netE.forward(image, inst.cuda())\n",
    "        inst_np = inst.cpu().numpy().astype(int)\n",
    "        feature = {}\n",
    "        #for i in range(self.opt.label_nc):\n",
    "        for i in range(0):\n",
    "            feature[i] = np.zeros((0, feat_num+1))\n",
    "        for i in np.unique(inst_np):\n",
    "            label = i if i < 1000 else i//1000\n",
    "            idx = (inst == int(i)).nonzero()\n",
    "            num = idx.size()[0]\n",
    "            idx = idx[num//2,:]\n",
    "            val = np.zeros((1, feat_num+1))                        \n",
    "            for k in range(feat_num):\n",
    "                val[0, k] = feat_map[idx[0], idx[1] + k, idx[2], idx[3]].data[0]            \n",
    "            val[0, feat_num] = float(num) / (h * w // block_num)\n",
    "            feature[label] = np.append(feature[label], val, axis=0)\n",
    "        return feature\n",
    "\n",
    "    def get_edges(self, t):\n",
    "        edge = torch.cuda.ByteTensor(t.size()).zero_()\n",
    "        edge[:,:,:,1:] = edge[:,:,:,1:] | (t[:,:,:,1:] != t[:,:,:,:-1])\n",
    "        edge[:,:,:,:-1] = edge[:,:,:,:-1] | (t[:,:,:,1:] != t[:,:,:,:-1])\n",
    "        edge[:,:,1:,:] = edge[:,:,1:,:] | (t[:,:,1:,:] != t[:,:,:-1,:])\n",
    "        edge[:,:,:-1,:] = edge[:,:,:-1,:] | (t[:,:,1:,:] != t[:,:,:-1,:])\n",
    "        #if self.opt.data_type==16:\n",
    "        if(32==16):\n",
    "            return edge.half()\n",
    "        else:\n",
    "            return edge.float()\n",
    "\n",
    "    def save(self, which_epoch):\n",
    "        self.save_network(self.netG, 'G', which_epoch, self.gpu_ids)\n",
    "        self.save_network(self.netD, 'D', which_epoch, self.gpu_ids)\n",
    "        if self.gen_features:\n",
    "            self.save_network(self.netE, 'E', which_epoch, self.gpu_ids)\n",
    "\n",
    "    def update_fixed_params(self):\n",
    "        # after fixing the global generator for a number of iterations, also start finetuning it\n",
    "        params = list(self.netG.parameters())\n",
    "        if self.gen_features:\n",
    "            params += list(self.netE.parameters())           \n",
    "        #self.optimizer_G = torch.optim.Adam(params, lr=self.opt.lr, betas=(self.opt.beta1, 0.999))\n",
    "        self.optimizer_G = torch.optim.Adam(params, lr=0.0002, betas=(0.5, 0.999))\n",
    "        if(False):                                                                                          #self.opt.verbose:\n",
    "            print('------------ Now also finetuning global generator -----------')\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        #lrd = self.opt.lr / self.opt.niter_decay\n",
    "        lrd = 0.0002 / 100\n",
    "        lr = self.old_lr - lrd        \n",
    "        for param_group in self.optimizer_D.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        for param_group in self.optimizer_G.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        if(False):                                                                                           #self.opt.verbose:\n",
    "            print('update learning rate: %f -> %f' % (self.old_lr, lr))\n",
    "        self.old_lr = lr\n",
    "\n",
    "class InferenceModel(Pix2PixHDModel):\n",
    "    def forward(self, inp):\n",
    "        label, inst = inp\n",
    "        return self.inference(label, inst)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6dab06-d78b-4f5c-b363-fbaeb843af4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (20): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (21): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (22): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (23): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (24): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (30): ReLU(inplace=True)\n",
      "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (39): Tanh()\n",
      "  )\n",
      ")\n",
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moose/miniconda3/envs/torch/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/moose/miniconda3/envs/torch/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = Pix2PixHDModel()\n",
    "model.initialize()\n",
    "model = torch.nn.DataParallel(model, device_ids=[0]).cuda()  # Move model to GPU and use DataParallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51e78b9-aec6-499e-8dca-76b8e9a88251",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f499e40e-dbb3-46fc-bdfe-966ee686beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8260/3082057046.py:89: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392035891/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Create dummy inputs with correct dimensions\n",
    "label = Variable(torch.rand(1, 3, 224, 224)).cuda()  # Assuming a single channel for label\n",
    "inst = Variable(torch.tensor([0])).cuda()   # Assuming a single channel for instance\n",
    "image = Variable(torch.rand(1, 3, 224, 224)).cuda()  # RGB image with 3 channels\n",
    "feat = Variable(torch.tensor([0])).cuda()   # Feature map (or set to None if not used)\n",
    "\n",
    "# Forward pass\n",
    "losses, generated = model(label, inst, \n",
    "            image, feat, infer=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed8fd9c-4c10-495d-aba4-715f312d4330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a690185-c937-40f5-86ff-0c125706f46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
