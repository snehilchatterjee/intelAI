{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a588a32e-b9d0-4e04-b237-2d7decbc1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from fastai.vision.learner import create_body\n",
    "from torch import nn\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46675bda-24dd-47fb-8301-1aa2bade0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time(model,ip,batch,cuda):\n",
    "    if(cuda):\n",
    "        model=model.to('cuda')\n",
    "        ip=ip.to('cuda')\n",
    "        print(f'Using cuda\\n')\n",
    "\n",
    "    start_time = 0\n",
    "    end_time = 0\n",
    "\n",
    "    # Avoiding init time\n",
    "    '''\n",
    "    we run some dummy examples through the network to do a ‘GPU warm-up.’ \n",
    "    This will automatically initialize the GPU and prevent it from going into power-saving mode \n",
    "    when we measure time. (https://deci.ai/blog/measure-inference-time-deep-neural-networks/)\n",
    "    '''\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        _ = model(ip) # GPU WARMUP\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        start_time = time.perf_counter()\n",
    "        _ = model(ip*5)                       # Multiplied by 5 to make sure old results aren't cached and just returned\n",
    "        end_time = time.perf_counter()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # Print the duration in seconds\n",
    "    print(f\"Duration: {duration} seconds\\nFPS: {batch/duration:.0f}\")\n",
    "\n",
    "    del ip\n",
    "    del model\n",
    "    del _\n",
    "    gc.collect()\n",
    "    if(cuda):\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a1c17f-c341-4f92-ba56-f51fadc174cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mobile_unet(n_input=3, n_output=3, size=224):\n",
    "    body = create_body(torchvision.models.mobilenet_v3_small(), n_in=n_input, pretrained=True, cut=-2)\n",
    "    net_G = DynamicUnet(body, n_output, (size, size))\n",
    "    return net_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c576f2-1a06-4cf6-a5b6-ec8b963c7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d=mobilenet_v3_small()\n",
    "model_d.classifier[3]=nn.Linear(in_features=1024,out_features=3,bias=True)\n",
    "\n",
    "model_g=build_mobile_unet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb841fd-f2d5-423a-987f-174a01c20656",
   "metadata": {},
   "source": [
    "#### Detection - method 1 (direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3834f986-6462-47a4-854f-19b5914935d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "Duration: 0.004365295000752667 seconds\n",
      "FPS: 229080\n"
     ]
    }
   ],
   "source": [
    "model_d.load_state_dict(torch.load('method1_(0.9811).pt'))\n",
    "calculate_time(model_d,torch.rand((1000,3,224,224)),1000,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00708db1-3859-4c49-ab4d-b1aa6b4a7e54",
   "metadata": {},
   "source": [
    "#### Detection - method 2 (edge detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2dfe91-9d74-493e-8aa4-98064edcc052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "Duration: 0.003870521999488119 seconds\n",
      "FPS: 258363\n"
     ]
    }
   ],
   "source": [
    "model_d.load_state_dict(torch.load('method2_(0.995).pt'))\n",
    "calculate_time(model_d,torch.rand((1000,3,224,224)),1000,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32dcd8-822e-44ea-9e65-48b65c67d97f",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c86c26b-22e5-46ae-a612-68ce5ef660bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "\n",
      "Duration: 0.004972920000000158 seconds\n",
      "FPS: 3217\n"
     ]
    }
   ],
   "source": [
    "calculate_time(model_g,torch.rand((16,3,224,224)),16,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
