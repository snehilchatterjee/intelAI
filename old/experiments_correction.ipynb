{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b293e210-21ef-4f72-a882-c7721c3e49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import functools\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b1e6f0-8275-451c-8b21-51768a4c7428",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430896ee-b255-47c7-801a-110da6b81f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPNHead(nn.Module):\n",
    "    def __init__(self, num_in, num_mid, num_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block0 = nn.Conv2d(num_in, num_mid, kernel_size=3, padding=1, bias=False)\n",
    "        self.block1 = nn.Conv2d(num_mid, num_out, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.block0(x), inplace=True)\n",
    "        x = nn.functional.relu(self.block1(x), inplace=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FPNMobileNet(nn.Module):\n",
    "\n",
    "    def __init__(self, norm_layer, output_ch=3, num_filters=64, num_filters_fpn=128, pretrained=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Feature Pyramid Network (FPN) with four feature maps of resolutions\n",
    "        # 1/4, 1/8, 1/16, 1/32 and `num_filters` filters for all feature maps.\n",
    "\n",
    "        self.fpn = FPN(num_filters=num_filters_fpn, norm_layer = norm_layer, pretrained=pretrained)\n",
    "\n",
    "        # The segmentation heads on top of the FPN\n",
    "\n",
    "        self.head1 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
    "        self.head2 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
    "        self.head3 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
    "        self.head4 = FPNHead(num_filters_fpn, num_filters, num_filters)\n",
    "\n",
    "        self.smooth = nn.Sequential(\n",
    "            nn.Conv2d(4 * num_filters, num_filters, kernel_size=3, padding=1),\n",
    "            norm_layer(num_filters),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.smooth2 = nn.Sequential(\n",
    "            nn.Conv2d(num_filters, num_filters // 2, kernel_size=3, padding=1),\n",
    "            norm_layer(num_filters // 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.final = nn.Conv2d(num_filters // 2, output_ch, kernel_size=3, padding=1)\n",
    "\n",
    "    def unfreeze(self):\n",
    "        self.fpn.unfreeze()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        map0, map1, map2, map3, map4 = self.fpn(x)\n",
    "\n",
    "        map4 = nn.functional.upsample(self.head4(map4), scale_factor=8, mode=\"nearest\")\n",
    "        map3 = nn.functional.upsample(self.head3(map3), scale_factor=4, mode=\"nearest\")\n",
    "        map2 = nn.functional.upsample(self.head2(map2), scale_factor=2, mode=\"nearest\")\n",
    "        map1 = nn.functional.upsample(self.head1(map1), scale_factor=1, mode=\"nearest\")\n",
    "\n",
    "        smoothed = self.smooth(torch.cat([map4, map3, map2, map1], dim=1))\n",
    "        smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n",
    "        smoothed = self.smooth2(smoothed + map0)\n",
    "        smoothed = nn.functional.upsample(smoothed, scale_factor=2, mode=\"nearest\")\n",
    "\n",
    "        final = self.final(smoothed)\n",
    "        res = torch.tanh(final) + x\n",
    "\n",
    "        return torch.clamp(res, min=-1, max=1)\n",
    "\n",
    "\n",
    "class FPN(nn.Module):\n",
    "\n",
    "    def __init__(self, norm_layer, num_filters=128, pretrained=True):\n",
    "        \"\"\"Creates an `FPN` instance for feature extraction.\n",
    "        Args:\n",
    "          num_filters: the number of filters in each output pyramid level\n",
    "          pretrained: use ImageNet pre-trained backbone feature extractor\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        net = MobileNetV2(n_class=1000)\n",
    "\n",
    "        if pretrained:\n",
    "            #Load weights into the project directory\n",
    "            state_dict = torch.load('mobilenetv2.pth.tar') # add map_location='cpu' if no gpu\n",
    "            net.load_state_dict(state_dict)\n",
    "        self.features = net.features\n",
    "\n",
    "        self.enc0 = nn.Sequential(*self.features[0:2])\n",
    "        self.enc1 = nn.Sequential(*self.features[2:4])\n",
    "        self.enc2 = nn.Sequential(*self.features[4:7])\n",
    "        self.enc3 = nn.Sequential(*self.features[7:11])\n",
    "        self.enc4 = nn.Sequential(*self.features[11:16])\n",
    "\n",
    "        self.td1 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n",
    "                                 norm_layer(num_filters),\n",
    "                                 nn.ReLU(inplace=True))\n",
    "        self.td2 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n",
    "                                 norm_layer(num_filters),\n",
    "                                 nn.ReLU(inplace=True))\n",
    "        self.td3 = nn.Sequential(nn.Conv2d(num_filters, num_filters, kernel_size=3, padding=1),\n",
    "                                 norm_layer(num_filters),\n",
    "                                 nn.ReLU(inplace=True))\n",
    "\n",
    "        self.lateral4 = nn.Conv2d(160, num_filters, kernel_size=1, bias=False)\n",
    "        self.lateral3 = nn.Conv2d(64, num_filters, kernel_size=1, bias=False)\n",
    "        self.lateral2 = nn.Conv2d(32, num_filters, kernel_size=1, bias=False)\n",
    "        self.lateral1 = nn.Conv2d(24, num_filters, kernel_size=1, bias=False)\n",
    "        self.lateral0 = nn.Conv2d(16, num_filters // 2, kernel_size=1, bias=False)\n",
    "\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze(self):\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Bottom-up pathway, from ResNet\n",
    "        enc0 = self.enc0(x)\n",
    "\n",
    "        enc1 = self.enc1(enc0) # 256\n",
    "\n",
    "        enc2 = self.enc2(enc1) # 512\n",
    "\n",
    "        enc3 = self.enc3(enc2) # 1024\n",
    "\n",
    "        enc4 = self.enc4(enc3) # 2048\n",
    "\n",
    "        # Lateral connections\n",
    "\n",
    "        lateral4 = self.lateral4(enc4)\n",
    "        lateral3 = self.lateral3(enc3)\n",
    "        lateral2 = self.lateral2(enc2)\n",
    "        lateral1 = self.lateral1(enc1)\n",
    "        lateral0 = self.lateral0(enc0)\n",
    "\n",
    "        # Top-down pathway\n",
    "        map4 = lateral4\n",
    "        map3 = self.td1(lateral3 + nn.functional.upsample(map4, scale_factor=2, mode=\"nearest\"))\n",
    "        map2 = self.td2(lateral2 + nn.functional.upsample(map3, scale_factor=2, mode=\"nearest\"))\n",
    "        map1 = self.td3(lateral1 + nn.functional.upsample(map2, scale_factor=2, mode=\"nearest\"))\n",
    "        return lateral0, map1, map2, map3, map4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add394ed-67db-42e5-8253-d3acf6ccdf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.last_channel = int(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, n_class),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835af80f-e64b-4cc4-8c01-74a97ac1bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_layer(norm_type='instance'):\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=True)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40982502-a7df-498f-a491-1bd1e5099b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g = FPNMobileNet(norm_layer=get_norm_layer(norm_type='instance'),pretrained=False)\n",
    "x=torch.rand((1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fd142fc-5a26-44c5-8d04-f3ddcddfc44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0.041198288999794386 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moose/miniconda3/envs/torch/lib/python3.11/site-packages/torch/nn/functional.py:3769: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "with torch.inference_mode():\n",
    "    model_g(x)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "duration = end_time - start_time\n",
    "\n",
    "# Print the duration in seconds\n",
    "print(f\"Duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda516e-bc3f-465f-8ab7-fcc3311c99f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
