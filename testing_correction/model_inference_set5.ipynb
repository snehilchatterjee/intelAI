{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import cv2\n",
    "from super_image import EdsrModel, ImageLoader\n",
    "import os\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using: {device}')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \n",
    "    class ResidualBlock(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, expansion=6, stride=1, alpha=1.0):\n",
    "            super(ResidualBlock, self).__init__()\n",
    "            self.expansion = expansion\n",
    "            self.stride = stride\n",
    "            self.in_channels = in_channels\n",
    "            self.out_channels = int(out_channels * alpha)\n",
    "            self.pointwise_conv_filters = self._make_divisible(self.out_channels, 8)\n",
    "            self.conv1 = nn.Conv2d(in_channels, in_channels * expansion, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "            self.bn1 = nn.BatchNorm2d(in_channels * expansion)\n",
    "            self.conv2 = nn.Conv2d(in_channels * expansion, in_channels * expansion, kernel_size=3, stride=stride, padding=1, groups=in_channels * expansion, bias=True)\n",
    "            self.bn2 = nn.BatchNorm2d(in_channels * expansion)\n",
    "            self.conv3 = nn.Conv2d(in_channels * expansion, self.pointwise_conv_filters, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "            self.bn3 = nn.BatchNorm2d(self.pointwise_conv_filters)\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.skip_add = (stride == 1 and in_channels == self.pointwise_conv_filters)\n",
    "\n",
    "        def forward(self, x):\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.bn1(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "            out = self.conv2(out)\n",
    "            out = self.bn2(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "            out = self.conv3(out)\n",
    "            out = self.bn3(out)\n",
    "\n",
    "            if self.skip_add:\n",
    "                out = out + identity\n",
    "\n",
    "            return out\n",
    "\n",
    "        @staticmethod\n",
    "        def _make_divisible(v, divisor, min_value=None):\n",
    "            if min_value is None:\n",
    "                min_value = divisor\n",
    "            new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "            if new_v < 0.9 * v:\n",
    "                new_v += divisor\n",
    "            return new_v\n",
    "\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, in_channels, num_residual_blocks, gf):\n",
    "            super(Generator, self).__init__()\n",
    "            self.num_residual_blocks = num_residual_blocks\n",
    "            self.gf = gf\n",
    "\n",
    "            self.conv1 = nn.Conv2d(in_channels, gf, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn1 = nn.BatchNorm2d(gf)\n",
    "            self.prelu1 = nn.PReLU()\n",
    "\n",
    "            self.residual_blocks = self.make_layer(ResidualBlock, gf, num_residual_blocks)\n",
    "\n",
    "            self.conv2 = nn.Conv2d(gf, gf, kernel_size=3, stride=1, padding=1)\n",
    "            self.bn2 = nn.BatchNorm2d(gf)\n",
    "\n",
    "            self.upsample1 = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "                nn.Conv2d(gf, gf, kernel_size=3, stride=1, padding=1),\n",
    "                nn.PReLU()\n",
    "            )\n",
    "\n",
    "            self.upsample2 = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "                nn.Conv2d(gf, gf, kernel_size=3, stride=1, padding=1),\n",
    "                nn.PReLU()\n",
    "            )\n",
    "\n",
    "            self.conv3 = nn.Conv2d(gf, 3, kernel_size=3, stride=1, padding=1)\n",
    "            self.tanh = nn.Tanh()\n",
    "\n",
    "        def make_layer(self, block, out_channels, blocks):\n",
    "            layers = []\n",
    "            for _ in range(blocks):\n",
    "                layers.append(block(out_channels, out_channels))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out1 = self.prelu1(self.bn1(self.conv1(x)))\n",
    "            out = self.residual_blocks(out1)\n",
    "            out = self.bn2(self.conv2(out))\n",
    "            out = out + out1\n",
    "            out = self.upsample1(out)\n",
    "            out = self.upsample2(out)\n",
    "            out = self.tanh(self.conv3(out))\n",
    "            return out\n",
    "\n",
    "    return Generator(3, 6, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _conv(nn.Conv2d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bias):\n",
    "        super(_conv, self).__init__(in_channels = in_channels, out_channels = out_channels, \n",
    "                               kernel_size = kernel_size, stride = stride, padding = (kernel_size) // 2, bias = True)\n",
    "        \n",
    "        self.weight.data = torch.normal(torch.zeros((out_channels, in_channels, kernel_size, kernel_size)), 0.02)\n",
    "        self.bias.data = torch.zeros((out_channels))\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "\n",
    "class conv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, BN = False, act = None, stride = 1, bias = True):\n",
    "        super(conv, self).__init__()\n",
    "        m = []\n",
    "        m.append(_conv(in_channels = in_channel, out_channels = out_channel, \n",
    "                               kernel_size = kernel_size, stride = stride, padding = (kernel_size) // 2, bias = True))\n",
    "        \n",
    "        if BN:\n",
    "            m.append(nn.BatchNorm2d(num_features = out_channel))\n",
    "        \n",
    "        if act is not None:\n",
    "            m.append(act)\n",
    "        \n",
    "        self.body = nn.Sequential(*m)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out\n",
    "        \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, act = nn.ReLU(inplace = True), bias = True):\n",
    "        super(ResBlock, self).__init__()\n",
    "        m = []\n",
    "        m.append(conv(channels, channels, kernel_size, BN = True, act = act))\n",
    "        m.append(conv(channels, channels, kernel_size, BN = True, act = None))\n",
    "        self.body = nn.Sequential(*m)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        res += x\n",
    "        return res\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_res_block, act = nn.ReLU(inplace = True)):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        m = []\n",
    "        \n",
    "        self.conv = conv(in_channels, out_channels, kernel_size, BN = False, act = act)\n",
    "        for i in range(num_res_block):\n",
    "            m.append(ResBlock(out_channels, kernel_size, act))\n",
    "        \n",
    "        m.append(conv(out_channels, out_channels, kernel_size, BN = True, act = None))\n",
    "        \n",
    "        self.body = nn.Sequential(*m)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.conv(x)\n",
    "        out = self.body(res)\n",
    "        out += res\n",
    "        \n",
    "        return out\n",
    "        \n",
    "class Upsampler(nn.Module):\n",
    "    def __init__(self, channel, kernel_size, scale, act = nn.ReLU(inplace = True)):\n",
    "        super(Upsampler, self).__init__()\n",
    "        m = []\n",
    "        m.append(conv(channel, channel * scale * scale, kernel_size))\n",
    "        m.append(nn.PixelShuffle(scale))\n",
    "    \n",
    "        if act is not None:\n",
    "            m.append(act)\n",
    "        \n",
    "        self.body = nn.Sequential(*m)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out\n",
    "\n",
    "class discrim_block(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, kernel_size, act = nn.LeakyReLU(inplace = True)):\n",
    "        super(discrim_block, self).__init__()\n",
    "        m = []\n",
    "        m.append(conv(in_feats, out_feats, kernel_size, BN = True, act = act))\n",
    "        m.append(conv(out_feats, out_feats, kernel_size, BN = True, act = act, stride = 2))\n",
    "        self.body = nn.Sequential(*m)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out\n",
    "\n",
    "class MiniSRGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_feat = 3, n_feats = 64, kernel_size = 3, num_block = 8, act = nn.PReLU(), scale=4):\n",
    "        super(MiniSRGAN, self).__init__()\n",
    "        \n",
    "        self.conv01 = conv(in_channel = img_feat, out_channel = n_feats, kernel_size = 9, BN = False, act = act)\n",
    "        \n",
    "        resblocks = [ResBlock(channels = n_feats, kernel_size = 3, act = act) for _ in range(num_block)]\n",
    "        self.body = nn.Sequential(*resblocks)\n",
    "        \n",
    "        self.conv02 = conv(in_channel = n_feats, out_channel = n_feats, kernel_size = 3, BN = True, act = None)\n",
    "        \n",
    "        if(scale == 4):\n",
    "            upsample_blocks = [Upsampler(channel = n_feats, kernel_size = 3, scale = 2, act = act) for _ in range(2)]\n",
    "        else:\n",
    "            upsample_blocks = [Upsampler(channel = n_feats, kernel_size = 3, scale = scale, act = act)]\n",
    "\n",
    "        self.tail = nn.Sequential(*upsample_blocks)\n",
    "        \n",
    "        self.last_conv = conv(in_channel = n_feats, out_channel = img_feat, kernel_size = 3, BN = False, act = nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv01(x)\n",
    "        _skip_connection = x\n",
    "        \n",
    "        x = self.body(x)\n",
    "        x = self.conv02(x)\n",
    "        feat = x + _skip_connection\n",
    "        \n",
    "        x = self.tail(feat)\n",
    "        x = self.last_conv(x)\n",
    "        \n",
    "        return x, feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FSRCNN (https://github.com/Lornatang/FSRCNN-PyTorch/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class FSRCNN(nn.Module):\n",
    "    def __init__(self, scale_factor, num_channels=1, d=56, s=12, m=4):\n",
    "        super(FSRCNN, self).__init__()\n",
    "        self.first_part = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, d, kernel_size=5, padding=5//2),\n",
    "            nn.PReLU(d)\n",
    "        )\n",
    "        self.mid_part = [nn.Conv2d(d, s, kernel_size=1), nn.PReLU(s)]\n",
    "        for _ in range(m):\n",
    "            self.mid_part.extend([nn.Conv2d(s, s, kernel_size=3, padding=3//2), nn.PReLU(s)])\n",
    "        self.mid_part.extend([nn.Conv2d(s, d, kernel_size=1), nn.PReLU(d)])\n",
    "        self.mid_part = nn.Sequential(*self.mid_part)\n",
    "        self.last_part = nn.ConvTranspose2d(d, num_channels, kernel_size=9, stride=scale_factor, padding=9//2,\n",
    "                                            output_padding=scale_factor-1)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.first_part:\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
    "                nn.init.zeros_(m.bias.data)\n",
    "        for m in self.mid_part:\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight.data, mean=0.0, std=math.sqrt(2/(m.out_channels*m.weight.data[0][0].numel())))\n",
    "                nn.init.zeros_(m.bias.data)\n",
    "        nn.init.normal_(self.last_part.weight.data, mean=0.0, std=0.001)\n",
    "        nn.init.zeros_(self.last_part.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_part(x)\n",
    "        x = self.mid_part(x)\n",
    "        x = self.last_part(x)\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_patch_size(func):\n",
    "    def wrapper(args):\n",
    "        if args.scale == 2:\n",
    "            args.patch_size = 10\n",
    "        elif args.scale == 3:\n",
    "            args.patch_size = 7\n",
    "        elif args.scale == 4:\n",
    "            args.patch_size = 6\n",
    "        else:\n",
    "            raise Exception('Scale Error', args.scale)\n",
    "        return func(args)\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def convert_rgb_to_y(img, dim_order='hwc'):\n",
    "    if dim_order == 'hwc':\n",
    "        return 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n",
    "    else:\n",
    "        return 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n",
    "\n",
    "\n",
    "def convert_rgb_to_ycbcr(img, dim_order='hwc'):\n",
    "    if dim_order == 'hwc':\n",
    "        y = 16. + (64.738 * img[..., 0] + 129.057 * img[..., 1] + 25.064 * img[..., 2]) / 256.\n",
    "        cb = 128. + (-37.945 * img[..., 0] - 74.494 * img[..., 1] + 112.439 * img[..., 2]) / 256.\n",
    "        cr = 128. + (112.439 * img[..., 0] - 94.154 * img[..., 1] - 18.285 * img[..., 2]) / 256.\n",
    "    else:\n",
    "        y = 16. + (64.738 * img[0] + 129.057 * img[1] + 25.064 * img[2]) / 256.\n",
    "        cb = 128. + (-37.945 * img[0] - 74.494 * img[1] + 112.439 * img[2]) / 256.\n",
    "        cr = 128. + (112.439 * img[0] - 94.154 * img[1] - 18.285 * img[2]) / 256.\n",
    "    return np.array([y, cb, cr]).transpose([1, 2, 0])\n",
    "\n",
    "\n",
    "def convert_ycbcr_to_rgb(img, dim_order='hwc'):\n",
    "    if dim_order == 'hwc':\n",
    "        r = 298.082 * img[..., 0] / 256. + 408.583 * img[..., 2] / 256. - 222.921\n",
    "        g = 298.082 * img[..., 0] / 256. - 100.291 * img[..., 1] / 256. - 208.120 * img[..., 2] / 256. + 135.576\n",
    "        b = 298.082 * img[..., 0] / 256. + 516.412 * img[..., 1] / 256. - 276.836\n",
    "    else:\n",
    "        r = 298.082 * img[0] / 256. + 408.583 * img[2] / 256. - 222.921\n",
    "        g = 298.082 * img[0] / 256. - 100.291 * img[1] / 256. - 208.120 * img[2] / 256. + 135.576\n",
    "        b = 298.082 * img[0] / 256. + 516.412 * img[1] / 256. - 276.836\n",
    "    return np.array([r, g, b]).transpose([1, 2, 0])\n",
    "\n",
    "\n",
    "def preprocess(img, device):\n",
    "    img = np.array(img).astype(np.float32)\n",
    "    ycbcr = convert_rgb_to_ycbcr(img)\n",
    "    x = ycbcr[..., 0]\n",
    "    x /= 255.\n",
    "    x = torch.from_numpy(x).to(device)\n",
    "    x = x.unsqueeze(0).unsqueeze(0)\n",
    "    return x, ycbcr\n",
    "\n",
    "\n",
    "def calc_psnr(img1, img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinySRGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_feat = 3, n_feats = 32, kernel_size = 3, num_block = 6, act = nn.PReLU(), scale=4):\n",
    "        super(TinySRGAN, self).__init__()\n",
    "        \n",
    "        self.conv01 = conv(in_channel = img_feat, out_channel = n_feats, kernel_size = 9, BN = False, act = act)\n",
    "        \n",
    "        resblocks = [ResBlock(channels = n_feats, kernel_size = 3, act = act) for _ in range(num_block)]\n",
    "        self.body = nn.Sequential(*resblocks)\n",
    "        \n",
    "        self.conv02 = conv(in_channel = n_feats, out_channel = n_feats, kernel_size = 3, BN = True, act = None)\n",
    "        \n",
    "        if(scale == 4):\n",
    "            upsample_blocks = [Upsampler(channel = n_feats, kernel_size = 3, scale = 2, act = act) for _ in range(2)]\n",
    "        else:\n",
    "            upsample_blocks = [Upsampler(channel = n_feats, kernel_size = 3, scale = scale, act = act)]\n",
    "\n",
    "        self.tail = nn.Sequential(*upsample_blocks)\n",
    "        \n",
    "        self.last_conv = conv(in_channel = n_feats, out_channel = img_feat, kernel_size = 3, BN = False, act = nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv01(x)\n",
    "        _skip_connection = x\n",
    "        \n",
    "        x = self.body(x)\n",
    "        x = self.conv02(x)\n",
    "        feat = x + _skip_connection\n",
    "        \n",
    "        x = self.tail(feat)\n",
    "        x = self.last_conv(x)\n",
    "        \n",
    "        return x, feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_feat = 3, n_feats = 64, kernel_size = 3, num_block = 16, act = nn.PReLU(), scale=4):\n",
    "        super(SRGAN, self).__init__()\n",
    "        \n",
    "        self.conv01 = conv(in_channel = img_feat, out_channel = n_feats, kernel_size = 9, BN = False, act = act)\n",
    "        \n",
    "        resblocks = [ResBlock(channels = n_feats, kernel_size = 3, act = act) for _ in range(num_block)]\n",
    "        self.body = nn.Sequential(*resblocks)\n",
    "        \n",
    "        self.conv02 = conv(in_channel = n_feats, out_channel = n_feats, kernel_size = 3, BN = True, act = None)\n",
    "        \n",
    "        if(scale == 4):\n",
    "            upsample_blocks = [Upsampler(channel = n_feats, kernel_size = 3, scale = 2, act = act) for _ in range(2)]\n",
    "        else:\n",
    "            upsample_blocks = [Upsampler(channel = n_feats, kernel_size = 3, scale = scale, act = act)]\n",
    "\n",
    "        self.tail = nn.Sequential(*upsample_blocks)\n",
    "        \n",
    "        self.last_conv = conv(in_channel = n_feats, out_channel = img_feat, kernel_size = 3, BN = False, act = nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv01(x)\n",
    "        _skip_connection = x\n",
    "        \n",
    "        x = self.body(x)\n",
    "        x = self.conv02(x)\n",
    "        feat = x + _skip_connection\n",
    "        \n",
    "        x = self.tail(feat)\n",
    "        x = self.last_conv(x)\n",
    "        \n",
    "        return x, feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpify(imgs):\n",
    "    all_images = []\n",
    "    for img in imgs:\n",
    "        img = img.permute(1,2,0).to('cpu') ### MIGHT CRASH HERE\n",
    "        all_images.append(img)\n",
    "    return np.stack(all_images, axis=0)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "def translate_image(image, sharpen, model_name, save):\n",
    "    print('Translating!')\n",
    "\n",
    "\n",
    "    if(model_name=='MobileSR'):\n",
    "        \n",
    "        model=build_generator().to(device)\n",
    "        model.load_state_dict(torch.load('../weights/mobile_sr.pt'))\n",
    "\n",
    "        low_res = transform(image)\n",
    "        low_res = low_res.unsqueeze(dim=0).to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            sr = model(low_res)\n",
    "            \n",
    "        fake_imgs = numpify(sr)\n",
    "        \n",
    "        sr_img = Image.fromarray((((fake_imgs[0] + 1) / 2) * 255).astype(np.uint8))\n",
    "\n",
    "    elif(model_name=='EDSR'):\n",
    "        model = EdsrModel.from_pretrained('eugenesiow/edsr-base', scale=4)    \n",
    "        inputs = ImageLoader.load_image(image)\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs)\n",
    "\n",
    "        sr_img = preds.data.cpu().numpy()\n",
    "        sr_img = sr_img[0].transpose((1, 2, 0)) * 255.0\n",
    "        sr_img = Image.fromarray(sr_img.astype(np.uint8))\n",
    "    elif(model_name=='MiniSRGAN'):\n",
    "        model = MiniSRGAN().to(device)\n",
    "        model.load_state_dict(torch.load('../weights/miniSRGAN.pt'))\n",
    "        \n",
    "        inputs = np.array(image)\n",
    "        inputs = (inputs / 127.5) - 1.0   \n",
    "        inputs = torch.tensor(inputs.transpose(2, 0, 1).astype(np.float32)).to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _ = model(torch.unsqueeze(inputs,dim=0))\n",
    "        output = output[0].cpu().numpy()\n",
    "        output = (output + 1.0) / 2.0\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        sr_img = Image.fromarray((output * 255.0).astype(np.uint8))\n",
    "    elif(model_name=='miniSRResNET'):\n",
    "        model = MiniSRGAN().to(device)\n",
    "        model.load_state_dict(torch.load('../weights/miniSRResNET.pt'))\n",
    "        \n",
    "        inputs = np.array(image)\n",
    "        inputs = (inputs / 127.5) - 1.0   \n",
    "        inputs = torch.tensor(inputs.transpose(2, 0, 1).astype(np.float32)).to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _ = model(torch.unsqueeze(inputs,dim=0))\n",
    "        output = output[0].cpu().numpy()\n",
    "        output = (output + 1.0) / 2.0\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        sr_img = Image.fromarray((output * 255.0).astype(np.uint8))\n",
    "    elif(model_name=='TinySRGAN'):\n",
    "        model = TinySRGAN().to(device)\n",
    "        model.load_state_dict(torch.load('../weights/tinySRGAN.pt'))\n",
    "        \n",
    "        inputs = np.array(image)\n",
    "        inputs = (inputs / 127.5) - 1.0   \n",
    "        inputs = torch.tensor(inputs.transpose(2, 0, 1).astype(np.float32)).to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _ = model(torch.unsqueeze(inputs,dim=0))\n",
    "        output = output[0].cpu().numpy()\n",
    "        output = (output + 1.0) / 2.0\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        sr_img = Image.fromarray((output * 255.0).astype(np.uint8))\n",
    "    elif(model_name=='SRGAN'):\n",
    "        model = SRGAN().to(device)\n",
    "        model.load_state_dict(torch.load('../weights/SRGAN.pt'))\n",
    "        \n",
    "        inputs = np.array(image)\n",
    "        inputs = (inputs / 127.5) - 1.0   \n",
    "        inputs = torch.tensor(inputs.transpose(2, 0, 1).astype(np.float32)).to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _ = model(torch.unsqueeze(inputs,dim=0))\n",
    "        output = output[0].cpu().numpy()\n",
    "        output = (output + 1.0) / 2.0\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        sr_img = Image.fromarray((output * 255.0).astype(np.uint8))\n",
    "    \n",
    "    if sharpen:\n",
    "        sr_img_cv = np.array(sr_img)\n",
    "        sr_img_cv = cv2.cvtColor(sr_img_cv, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharpened_sr_img_cv = cv2.filter2D(sr_img_cv, -1, kernel)\n",
    "        \n",
    "        sharpened_sr_img = Image.fromarray(cv2.cvtColor(sharpened_sr_img_cv, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if(save==\"True\"):\n",
    "            sharpened_sr_img.save('super_resolved_image.png')\n",
    "        \n",
    "        return sharpened_sr_img\n",
    "    else:\n",
    "        \n",
    "        if(save==\"True\"):\n",
    "            sr_img.save('super_resolved_image.png')\n",
    "        \n",
    "        return sr_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3.png...\n",
      "Translating!\n",
      "Processing 2.png...\n",
      "Translating!\n",
      "Processing 5.png...\n",
      "Translating!\n",
      "Processing 1.png...\n",
      "Translating!\n",
      "Processing 4.png...\n",
      "Translating!\n"
     ]
    }
   ],
   "source": [
    "degraded_images = os.listdir('./Set5/image_SRF_4/LR')\n",
    "for image_name in degraded_images:\n",
    "    print(f\"Processing {image_name}...\")\n",
    "    image_path=os.path.join('./Set5/image_SRF_4/LR', image_name)\n",
    "    image = Image.open(image_path)\n",
    "    sr_img = translate_image(image, sharpen=False, model_name='MobileSR', save='False')\n",
    "    if(os.path.exists('./super_resolved_Set5_images_mobileSR')==False):\n",
    "        os.mkdir('./super_resolved_Set5_images_mobileSR')\n",
    "    else:\n",
    "        sr_img.save(f'./super_resolved_Set5_images_mobileSR/{image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3.png...\n",
      "Translating!\n",
      "Processing 2.png...\n",
      "Translating!\n",
      "Processing 5.png...\n",
      "Translating!\n",
      "Processing 1.png...\n",
      "Translating!\n",
      "Processing 4.png...\n",
      "Translating!\n"
     ]
    }
   ],
   "source": [
    "degraded_images = os.listdir('./Set5/image_SRF_4/LR')\n",
    "for image_name in degraded_images:\n",
    "    print(f\"Processing {image_name}...\")\n",
    "    image_path=os.path.join('./Set5/image_SRF_4/LR', image_name)\n",
    "    image = Image.open(image_path)\n",
    "    sr_img = translate_image(image, sharpen=False, model_name='MiniSRGAN', save='False')\n",
    "    if(os.path.exists('./super_resolved_Set5_images_miniSRGAN')==False):\n",
    "        os.mkdir('./super_resolved_Set5_images_miniSRGAN')\n",
    "    else:\n",
    "        sr_img.save(f'./super_resolved_Set5_images_miniSRGAN/{image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3.png...\n",
      "Translating!\n",
      "https://huggingface.co/eugenesiow/edsr-base/resolve/main/pytorch_model_4x.pt\n",
      "Processing 2.png...\n",
      "Translating!\n",
      "https://huggingface.co/eugenesiow/edsr-base/resolve/main/pytorch_model_4x.pt\n",
      "Processing 5.png...\n",
      "Translating!\n",
      "https://huggingface.co/eugenesiow/edsr-base/resolve/main/pytorch_model_4x.pt\n",
      "Processing 1.png...\n",
      "Translating!\n",
      "https://huggingface.co/eugenesiow/edsr-base/resolve/main/pytorch_model_4x.pt\n",
      "Processing 4.png...\n",
      "Translating!\n",
      "https://huggingface.co/eugenesiow/edsr-base/resolve/main/pytorch_model_4x.pt\n"
     ]
    }
   ],
   "source": [
    "degraded_images = os.listdir('./Set5/image_SRF_4/LR')\n",
    "for image_name in degraded_images:\n",
    "    print(f\"Processing {image_name}...\")\n",
    "    image_path=os.path.join('./Set5/image_SRF_4/LR', image_name)\n",
    "    image = Image.open(image_path)\n",
    "    sr_img = translate_image(image, sharpen=False, model_name='EDSR', save='False')\n",
    "    if(os.path.exists('./super_resolved_Set5_images_EDSR')==False):\n",
    "        os.mkdir('./super_resolved_Set5_images_EDSR')\n",
    "    else:\n",
    "        sr_img.save(f'./super_resolved_Set5_images_EDSR/{image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3.png...\n",
      "Translating!\n",
      "Processing 2.png...\n",
      "Translating!\n",
      "Processing 5.png...\n",
      "Translating!\n",
      "Processing 1.png...\n",
      "Translating!\n",
      "Processing 4.png...\n",
      "Translating!\n"
     ]
    }
   ],
   "source": [
    "degraded_images = os.listdir('../../../../Set5/image_SRF_4/LR')\n",
    "for image_name in degraded_images:\n",
    "    print(f\"Processing {image_name}...\")\n",
    "    image_path=os.path.join('../../../../Set5/image_SRF_4/LR', image_name)\n",
    "    image = Image.open(image_path)\n",
    "    sr_img = translate_image(image, sharpen=False, model_name='miniSRResNET', save='False')\n",
    "    if(os.path.exists('./super_resolved_Set5_images_miniSRResNET')==False):\n",
    "        os.mkdir('./super_resolved_Set5_images_miniSRResNET')\n",
    "    else:\n",
    "        sr_img.save(f'./super_resolved_Set5_images_miniSRResNET/{image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3.png...\n",
      "Translating!\n",
      "Processing 2.png...\n",
      "Translating!\n",
      "Processing 5.png...\n",
      "Translating!\n",
      "Processing 1.png...\n",
      "Translating!\n",
      "Processing 4.png...\n",
      "Translating!\n"
     ]
    }
   ],
   "source": [
    "degraded_images = os.listdir('../../../../Set5/image_SRF_4/LR')\n",
    "for image_name in degraded_images:\n",
    "    print(f\"Processing {image_name}...\")\n",
    "    image_path=os.path.join('../../../../Set5/image_SRF_4/LR', image_name)\n",
    "    image = Image.open(image_path)\n",
    "    sr_img = translate_image(image, sharpen=False, model_name='TinySRGAN', save='False')\n",
    "    if(os.path.exists('./super_resolved_Set5_images_tinySRGAN')==False):\n",
    "        os.mkdir('./super_resolved_Set5_images_tinySRGAN')\n",
    "    else:\n",
    "        sr_img.save(f'./super_resolved_Set5_images_tinySRGAN/{image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3.png...\n",
      "Translating!\n",
      "Processing 2.png...\n",
      "Translating!\n",
      "Processing 5.png...\n",
      "Translating!\n",
      "Processing 1.png...\n",
      "Translating!\n",
      "Processing 4.png...\n",
      "Translating!\n"
     ]
    }
   ],
   "source": [
    "degraded_images = os.listdir('../../../../Set5/image_SRF_4/LR')\n",
    "for image_name in degraded_images:\n",
    "    print(f\"Processing {image_name}...\")\n",
    "    image_path=os.path.join('../../../../Set5/image_SRF_4/LR', image_name)\n",
    "    image = Image.open(image_path)\n",
    "    sr_img = translate_image(image, sharpen=False, model_name='SRGAN', save='False')\n",
    "    if(os.path.exists('./super_resolved_Set5_images_srgan')==False):\n",
    "        os.mkdir('./super_resolved_Set5_images_srgan')\n",
    "    else:\n",
    "        sr_img.save(f'./super_resolved_Set5_images_srgan/{image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3.png...\n",
      "PSNR: 25.33\n",
      "Processing 2.png...\n",
      "PSNR: 32.46\n",
      "Processing 5.png...\n",
      "PSNR: 29.11\n",
      "Processing 1.png...\n",
      "PSNR: 33.14\n",
      "Processing 4.png...\n",
      "PSNR: 32.47\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as pil_image\n",
    "import os \n",
    "\n",
    "model=FSRCNN(scale_factor=4).to(device)\n",
    "state_dict = model.state_dict()\n",
    "for n, p in torch.load('../weights/fsrcnn_x4.pth', map_location=lambda storage, loc: storage).items():\n",
    "    if n in state_dict.keys():\n",
    "        state_dict[n].copy_(p)\n",
    "    else:\n",
    "        raise KeyError(n)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "scale=4\n",
    "\n",
    "degraded_images = os.listdir('../../../../Set5/image_SRF_4/HR')\n",
    "for image_name in degraded_images:\n",
    "    print(f\"Processing {image_name}...\")\n",
    "    image_path=os.path.join('../../../../Set5/image_SRF_4/HR', image_name)\n",
    "    image = pil_image.open(image_path)\n",
    "    \n",
    "    image_width = (image.width // scale) * scale\n",
    "    image_height = (image.height // scale) * scale\n",
    "    \n",
    "    hr = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "    lr = hr.resize((hr.width // scale, hr.height // scale), resample=pil_image.BICUBIC)\n",
    "    bicubic = lr.resize((lr.width * scale, lr.height * scale), resample=pil_image.BICUBIC)\n",
    "    #bicubic.save(image_file.replace('.', '_bicubic_x{}.'.format(scale)))\n",
    "\n",
    "    \n",
    "    lr, _ = preprocess(lr, device)\n",
    "    hr, _ = preprocess(hr, device)\n",
    "    _, ycbcr = preprocess(bicubic, device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(lr).clamp(0.0, 1.0)\n",
    "\n",
    "    psnr = calc_psnr(hr, preds)\n",
    "    print('PSNR: {:.2f}'.format(psnr))\n",
    "\n",
    "    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
    "    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "    sr_img = pil_image.fromarray(output)\n",
    "\n",
    "    #sr_img = translate_image(image, sharpen=False, model_name='miniSRResNET', save='False')\n",
    "    \n",
    "    \n",
    "    if(os.path.exists('./super_resolved_Set5_images_FSRCNN')==False):\n",
    "        os.mkdir('./super_resolved_Set5_images_FSRCNN')\n",
    "    else:\n",
    "        sr_img.save(f'./super_resolved_Set5_images_FSRCNN/{image_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
