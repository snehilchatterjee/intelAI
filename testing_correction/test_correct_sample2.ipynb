{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "import lpips\n",
    "\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using: {device}')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR (proposed method):\n",
      "PSNR: 28.95 dB, SSIM: 0.7582, LPIPS: 0.3794\n",
      "Metrics for HR vs SR (bicubic):\n",
      "PSNR: 27.23 dB, SSIM: 0.6684, LPIPS: 0.2878\n"
     ]
    }
   ],
   "source": [
    "def calculate_psnr(img1, img2):\n",
    "    # Convert images to float32\n",
    "    img1 = img1.astype(np.float32)\n",
    "    img2 = img2.astype(np.float32)\n",
    "    \n",
    "    # Compute MSE\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    \n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    \n",
    "    return psnr\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    # Convert images to grayscale (if needed)\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute SSIM\n",
    "    ssim_value, _ = ssim(img1_gray, img2_gray, full=True)\n",
    "    \n",
    "    return ssim_value\n",
    "\n",
    "def calculate_lpips(img1, img2):\n",
    "    # Create the LPIPS metric\n",
    "    loss_fn = lpips.LPIPS(net='alex', verbose=False)\n",
    "    \n",
    "    # Convert images to PyTorch tensors\n",
    "    img1_tensor = lpips.im2tensor(img1)\n",
    "    img2_tensor = lpips.im2tensor(img2)\n",
    "    \n",
    "    # Calculate LPIPS distance\n",
    "    lpips_value = loss_fn(img1_tensor, img2_tensor)\n",
    "    \n",
    "    return lpips_value.item()\n",
    "\n",
    "def compare_metrics(hr_img, sr_img, lr_img):\n",
    "    # Calculate metrics for HR vs SR\n",
    "    psnr_hr_sr = calculate_psnr(hr_img, sr_img)\n",
    "    ssim_hr_sr = calculate_ssim(hr_img, sr_img)\n",
    "    lpips_hr_sr = calculate_lpips(hr_img, sr_img)\n",
    "    \n",
    "    # Calculate metrics for HR vs LR\n",
    "    psnr_hr_lr = calculate_psnr(hr_img, lr_img)\n",
    "    ssim_hr_lr = calculate_ssim(hr_img, lr_img)\n",
    "    lpips_hr_lr = calculate_lpips(hr_img, lr_img)\n",
    "    \n",
    "    # Calculate metrics for HR vs Bicubic SR (for comparison)\n",
    "    bicubic_sr_img = cv2.resize(lr_img, (hr_img.shape[1], hr_img.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "    psnr_hr_bicubic = calculate_psnr(hr_img, bicubic_sr_img)\n",
    "    ssim_hr_bicubic = calculate_ssim(hr_img, bicubic_sr_img)\n",
    "    lpips_hr_bicubic = calculate_lpips(hr_img, bicubic_sr_img)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Metrics for HR vs SR (proposed method):\")\n",
    "    print(f\"PSNR: {psnr_hr_sr:.2f} dB, SSIM: {ssim_hr_sr:.4f}, LPIPS: {lpips_hr_sr:.4f}\")\n",
    "    print(\"Metrics for HR vs SR (bicubic):\")\n",
    "    print(f\"PSNR: {psnr_hr_lr:.2f} dB, SSIM: {ssim_hr_lr:.4f}, LPIPS: {lpips_hr_lr:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "hr_image_path = '../Sample_2.jpg'\n",
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_mobileSR.png'  # Super-resolved image\n",
    "lr_image_path = '../experiment_detection/solo_2/Upscaled Image 914x609.png'  # Low-resolution image\n",
    "\n",
    "hr_img = cv2.imread(hr_image_path)\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "lr_img = cv2.imread(lr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img, lr_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR (proposed method):\n",
      "PSNR: 27.41 dB, SSIM: 0.7154, LPIPS: 0.7205\n",
      "Metrics for HR vs SR (bicubic):\n",
      "PSNR: 27.23 dB, SSIM: 0.6684, LPIPS: 0.2878\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_miniSRGAN.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img, lr_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR (proposed method):\n",
      "PSNR: 29.19 dB, SSIM: 0.7657, LPIPS: 0.6461\n",
      "Metrics for HR vs SR (bicubic):\n",
      "PSNR: 27.23 dB, SSIM: 0.6684, LPIPS: 0.2878\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_EDSR.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img, lr_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
