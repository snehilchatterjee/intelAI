{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.color import rgb2ycbcr\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "import lpips\n",
    "\n",
    "\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using: {device}')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(gt, sr):\n",
    "    scale=4\n",
    "    \n",
    "    y_output = rgb2ycbcr(sr)[:, :, 0] # https://in.mathworks.com/help/vision/ref/psnr.html\n",
    "    y_gt = rgb2ycbcr(gt)[:, :, 0]\n",
    "    \n",
    "    y_output = y_output[scale:-scale, scale:-scale]\n",
    "    y_gt = y_gt[scale:-scale, scale:-scale]\n",
    "    \n",
    "    \n",
    "    # Normalize to range [0, 1]\n",
    "    y_output_norm = y_output / 255.0\n",
    "    y_gt_norm = y_gt / 255.0\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    psnr_value = peak_signal_noise_ratio(y_output_norm, y_gt_norm, data_range=1.0)\n",
    "    \n",
    "    return psnr_value\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    # Convert images to grayscale (if needed)\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute SSIM\n",
    "    ssim_value, _ = ssim(img1_gray, img2_gray, full=True)\n",
    "    \n",
    "    return ssim_value\n",
    "\n",
    "def calculate_lpips(img1, img2):\n",
    "    # Create the LPIPS metric\n",
    "    loss_fn = lpips.LPIPS(net='alex', verbose=False)\n",
    "    \n",
    "    # Convert images to PyTorch tensors\n",
    "    img1_tensor = lpips.im2tensor(img1)\n",
    "    img2_tensor = lpips.im2tensor(img2)\n",
    "    \n",
    "    # Calculate LPIPS distance\n",
    "    lpips_value = loss_fn(img1_tensor, img2_tensor)\n",
    "    \n",
    "    return lpips_value.item()\n",
    "\n",
    "\n",
    "def compare_metrics(hr_img, sr_img):\n",
    "    # Calculate metrics for HR vs SR\n",
    "    psnr_hr_sr = calculate_psnr(hr_img, sr_img)\n",
    "    ssim_hr_sr = calculate_ssim(hr_img, sr_img)\n",
    "    lpips_hr_sr = calculate_lpips(hr_img, sr_img)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"Metrics for HR vs SR:\")\n",
    "    print(f\"PSNR: {psnr_hr_sr:.2f} dB, SSIM: {ssim_hr_sr:.4f}, LPIPS: {lpips_hr_sr:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "hr_image_path = '../Sample_2.jpg'\n",
    "lr_image_path = '../experiment_detection/solo_2/Upscaled Image 914x609.png'  # Low-resolution image\n",
    "\n",
    "hr_img = cv2.imread(hr_image_path)\n",
    "lr_img = cv2.imread(lr_image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bicubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR:\n",
      "PSNR: 28.57 dB, SSIM: 0.6684, LPIPS: 0.2878\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../experiment_detection/solo_2/Upscaled Image 914x609.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobile SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR:\n",
      "PSNR: 27.77 dB, SSIM: 0.6254, LPIPS: 0.3170\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_mobileSR.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniSRResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR:\n",
      "PSNR: 30.49 dB, SSIM: 0.7643, LPIPS: 0.6455\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_miniSRResNET.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniSRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR:\n",
      "PSNR: 30.32 dB, SSIM: 0.7389, LPIPS: 0.3661\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_miniSRGAN.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR:\n",
      "PSNR: 30.44 dB, SSIM: 0.7604, LPIPS: 0.5985\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_FSRCNN.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR:\n",
      "PSNR: 30.54 dB, SSIM: 0.7657, LPIPS: 0.6461\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_EDSR.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RealESRGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for HR vs SR:\n",
      "PSNR: 28.82 dB, SSIM: 0.7359, LPIPS: 0.4633\n"
     ]
    }
   ],
   "source": [
    "sr_image_path = '../sample2_correction_model_results/Upscaled Image 914x609_RealESRGAN.png'  # Super-resolved image\n",
    "sr_img = cv2.imread(sr_image_path)\n",
    "\n",
    "compare_metrics(hr_img, sr_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
